2020-09-12 17:19:28
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets2
     train            file: train.csv
     validation       file: dev.csv
     vocab             dir: data/example_datasets2/vocabs
     delimiter            : b
     use              bert: True
     checkpoints       dir: checkpoints/datasets2
     log               dir: data/example_datasets2/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['ORG', 'PER', 'LOC']
     labeling_level       : char
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 768
     max  sequence  length: 300
     hidden            dim: 200
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 42
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 300
     batch            size: 32
     dropout              : 0.5
     learning         rate: 0.001
     optimizer            : Adam
     checkpoint       name: model
     max       checkpoints: 3
     print       per_batch: 20
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
label vocab files not exist, building label vocab...
mode: train
loading data...
loading data...
training set size: 23181, validating set size: 4636
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/300
training batch:    20, loss: 20.31601, precision: 0.000 recall: 0.000 f1: -1.000 accuracy: 0.882 
training batch:    40, loss: 11.16911, precision: 0.429 recall: 0.095 f1: 0.156 accuracy: 0.936 
training batch:    60, loss: 6.58738, precision: 0.875 recall: 0.538 f1: 0.667 accuracy: 0.955 
training batch:    80, loss: 5.20128, precision: 0.686 recall: 0.648 f1: 0.667 accuracy: 0.961 
training batch:   100, loss: 5.72604, precision: 0.720 recall: 0.600 f1: 0.655 accuracy: 0.960 
training batch:   120, loss: 4.19503, precision: 0.731 recall: 0.760 f1: 0.745 accuracy: 0.971 
training batch:   140, loss: 2.64740, precision: 0.857 recall: 0.766 f1: 0.809 accuracy: 0.980 
training batch:   160, loss: 4.19385, precision: 0.758 recall: 0.712 f1: 0.734 accuracy: 0.977 
training batch:   180, loss: 3.31286, precision: 0.847 recall: 0.769 f1: 0.806 accuracy: 0.978 
training batch:   200, loss: 6.20847, precision: 0.804 recall: 0.707 f1: 0.752 accuracy: 0.963 
training batch:   220, loss: 4.01629, precision: 0.698 recall: 0.638 f1: 0.667 accuracy: 0.966 
training batch:   240, loss: 1.61347, precision: 0.852 recall: 0.852 f1: 0.852 accuracy: 0.989 
training batch:   260, loss: 2.57976, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.985 
training batch:   280, loss: 3.56211, precision: 0.786 recall: 0.635 f1: 0.702 accuracy: 0.968 
training batch:   300, loss: 1.50657, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.990 
training batch:   320, loss: 2.07309, precision: 0.854 recall: 0.837 f1: 0.845 accuracy: 0.981 
training batch:   340, loss: 2.05344, precision: 0.935 recall: 0.935 f1: 0.935 accuracy: 0.988 
training batch:   360, loss: 1.82579, precision: 0.882 recall: 0.833 f1: 0.857 accuracy: 0.987 
training batch:   380, loss: 2.18855, precision: 0.889 recall: 0.836 f1: 0.862 accuracy: 0.985 
training batch:   400, loss: 2.30946, precision: 0.912 recall: 0.825 f1: 0.867 accuracy: 0.984 
training batch:   420, loss: 2.86941, precision: 0.917 recall: 0.902 f1: 0.909 accuracy: 0.981 
training batch:   440, loss: 1.63527, precision: 0.927 recall: 0.864 f1: 0.895 accuracy: 0.990 
training batch:   460, loss: 2.27520, precision: 0.877 recall: 0.905 f1: 0.891 accuracy: 0.980 
training batch:   480, loss: 2.73518, precision: 0.815 recall: 0.898 f1: 0.855 accuracy: 0.972 
training batch:   500, loss: 2.89375, precision: 0.855 recall: 0.878 f1: 0.867 accuracy: 0.983 
training batch:   520, loss: 2.50329, precision: 0.879 recall: 0.761 f1: 0.816 accuracy: 0.982 
training batch:   540, loss: 2.75203, precision: 0.830 recall: 0.800 f1: 0.815 accuracy: 0.983 
training batch:   560, loss: 1.97422, precision: 0.913 recall: 0.875 f1: 0.894 accuracy: 0.987 
training batch:   580, loss: 3.28820, precision: 0.880 recall: 0.859 f1: 0.869 accuracy: 0.975 
training batch:   600, loss: 1.94211, precision: 0.822 recall: 0.841 f1: 0.831 accuracy: 0.984 
training batch:   620, loss: 1.17232, precision: 0.915 recall: 0.915 f1: 0.915 accuracy: 0.991 
training batch:   640, loss: 3.61680, precision: 0.925 recall: 0.860 f1: 0.891 accuracy: 0.977 
training batch:   660, loss: 2.20174, precision: 0.805 recall: 0.846 f1: 0.825 accuracy: 0.977 
training batch:   680, loss: 1.35900, precision: 0.912 recall: 0.881 f1: 0.897 accuracy: 0.990 
training batch:   700, loss: 3.85001, precision: 0.896 recall: 0.811 f1: 0.851 accuracy: 0.971 
training batch:   720, loss: 0.89702, precision: 0.881 recall: 0.902 f1: 0.892 accuracy: 0.992 
start evaluate engines...
label: ORG, precision: 0.815 recall: 0.815 f1: 0.807 accuracy: 0.000 
label: PER, precision: 0.923 recall: 0.938 f1: 0.928 accuracy: 0.000 
label: LOC, precision: 0.880 recall: 0.874 f1: 0.873 accuracy: 0.000 
time consumption:84.99(min), precision: 0.902 recall: 0.899 f1: 0.900 accuracy: 0.988 
saved the new best model with f1: 0.900
epoch:2/300
training batch:    20, loss: 5.20091, precision: 0.774 recall: 0.774 f1: 0.774 accuracy: 0.972 
training batch:    40, loss: 2.11478, precision: 0.821 recall: 0.793 f1: 0.807 accuracy: 0.982 
training batch:    60, loss: 1.23341, precision: 0.880 recall: 0.880 f1: 0.880 accuracy: 0.988 
training batch:    80, loss: 1.60728, precision: 0.851 recall: 0.870 f1: 0.860 accuracy: 0.982 
training batch:   100, loss: 3.80636, precision: 0.938 recall: 0.865 f1: 0.900 accuracy: 0.983 
training batch:   120, loss: 1.28798, precision: 0.943 recall: 0.893 f1: 0.917 accuracy: 0.994 
training batch:   140, loss: 2.16428, precision: 0.870 recall: 0.889 f1: 0.879 accuracy: 0.984 
training batch:   160, loss: 0.88489, precision: 0.886 recall: 0.912 f1: 0.899 accuracy: 0.994 
training batch:   180, loss: 1.17688, precision: 0.902 recall: 0.859 f1: 0.880 accuracy: 0.992 
training batch:   200, loss: 2.54661, precision: 0.812 recall: 0.830 f1: 0.821 accuracy: 0.983 
training batch:   220, loss: 1.32963, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.987 
training batch:   240, loss: 2.45092, precision: 0.826 recall: 0.864 f1: 0.844 accuracy: 0.979 
training batch:   260, loss: 1.30333, precision: 0.907 recall: 0.860 f1: 0.883 accuracy: 0.987 
training batch:   280, loss: 1.11956, precision: 0.913 recall: 0.933 f1: 0.923 accuracy: 0.993 
training batch:   300, loss: 0.32639, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.999 
training batch:   320, loss: 1.33732, precision: 0.816 recall: 0.886 f1: 0.849 accuracy: 0.990 
training batch:   340, loss: 0.91501, precision: 0.915 recall: 0.915 f1: 0.915 accuracy: 0.993 
training batch:   360, loss: 1.68026, precision: 0.953 recall: 0.872 f1: 0.911 accuracy: 0.986 
training batch:   380, loss: 1.35888, precision: 0.945 recall: 0.912 f1: 0.929 accuracy: 0.989 
training batch:   400, loss: 3.32369, precision: 0.829 recall: 0.795 f1: 0.811 accuracy: 0.974 
training batch:   420, loss: 1.53200, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.988 
training batch:   440, loss: 1.52072, precision: 0.872 recall: 0.804 f1: 0.837 accuracy: 0.983 
training batch:   460, loss: 0.86101, precision: 0.861 recall: 0.886 f1: 0.873 accuracy: 0.994 
training batch:   480, loss: 1.43751, precision: 0.945 recall: 0.852 f1: 0.897 accuracy: 0.985 
training batch:   500, loss: 2.77247, precision: 0.769 recall: 0.857 f1: 0.811 accuracy: 0.980 
training batch:   520, loss: 1.16489, precision: 0.908 recall: 0.881 f1: 0.894 accuracy: 0.991 
training batch:   540, loss: 1.11603, precision: 0.886 recall: 0.816 f1: 0.849 accuracy: 0.988 
training batch:   560, loss: 1.20470, precision: 0.902 recall: 0.932 f1: 0.917 accuracy: 0.989 
training batch:   580, loss: 1.49013, precision: 0.889 recall: 0.857 f1: 0.873 accuracy: 0.988 
training batch:   600, loss: 2.29464, precision: 0.867 recall: 0.830 f1: 0.848 accuracy: 0.980 
training batch:   620, loss: 1.32693, precision: 0.927 recall: 0.864 f1: 0.894 accuracy: 0.984 
training batch:   640, loss: 2.66146, precision: 0.837 recall: 0.774 f1: 0.804 accuracy: 0.981 
training batch:   660, loss: 2.24672, precision: 0.869 recall: 0.828 f1: 0.848 accuracy: 0.987 
training batch:   680, loss: 0.77867, precision: 0.918 recall: 0.918 f1: 0.918 accuracy: 0.996 
training batch:   700, loss: 0.60343, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.996 
training batch:   720, loss: 0.64936, precision: 0.945 recall: 0.929 f1: 0.937 accuracy: 0.991 
start evaluate engines...
label: ORG, precision: 0.826 recall: 0.858 f1: 0.832 accuracy: 0.000 
label: PER, precision: 0.944 recall: 0.943 f1: 0.941 accuracy: 0.000 
label: LOC, precision: 0.892 recall: 0.910 f1: 0.897 accuracy: 0.000 
time consumption:84.39(min), precision: 0.909 recall: 0.921 f1: 0.914 accuracy: 0.989 
saved the new best model with f1: 0.914
epoch:3/300
training batch:    20, loss: 2.09167, precision: 0.940 recall: 0.963 f1: 0.951 accuracy: 0.983 
training batch:    40, loss: 0.53100, precision: 0.911 recall: 0.953 f1: 0.932 accuracy: 0.996 
training batch:    60, loss: 1.26966, precision: 0.885 recall: 0.857 f1: 0.871 accuracy: 0.988 
training batch:    80, loss: 1.59498, precision: 0.967 recall: 0.951 f1: 0.959 accuracy: 0.987 
training batch:   100, loss: 1.58410, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.991 
training batch:   120, loss: 1.42140, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.989 
training batch:   140, loss: 1.87391, precision: 0.907 recall: 0.942 f1: 0.925 accuracy: 0.989 
training batch:   160, loss: 0.63870, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.992 
training batch:   180, loss: 0.71806, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.996 
training batch:   200, loss: 1.32033, precision: 0.915 recall: 0.942 f1: 0.929 accuracy: 0.986 
training batch:   220, loss: 1.37284, precision: 0.902 recall: 0.859 f1: 0.880 accuracy: 0.985 
training batch:   240, loss: 0.85032, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.988 
training batch:   260, loss: 1.41689, precision: 0.969 recall: 0.899 f1: 0.932 accuracy: 0.989 
training batch:   280, loss: 0.55304, precision: 1.000 recall: 0.983 f1: 0.991 accuracy: 0.997 
training batch:   300, loss: 1.21773, precision: 0.897 recall: 0.875 f1: 0.886 accuracy: 0.989 
training batch:   320, loss: 1.13041, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.989 
training batch:   340, loss: 1.07263, precision: 0.951 recall: 0.921 f1: 0.935 accuracy: 0.988 
training batch:   360, loss: 0.93937, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.994 
training batch:   380, loss: 0.70443, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.996 
training batch:   400, loss: 1.63851, precision: 0.922 recall: 0.894 f1: 0.908 accuracy: 0.985 
training batch:   420, loss: 1.41050, precision: 0.846 recall: 0.815 f1: 0.830 accuracy: 0.986 
training batch:   440, loss: 0.49077, precision: 0.920 recall: 0.868 f1: 0.893 accuracy: 0.996 
training batch:   460, loss: 0.60419, precision: 1.000 recall: 0.981 f1: 0.990 accuracy: 0.998 
training batch:   480, loss: 1.96019, precision: 0.914 recall: 0.914 f1: 0.914 accuracy: 0.982 
training batch:   500, loss: 1.39562, precision: 0.947 recall: 0.915 f1: 0.931 accuracy: 0.989 
training batch:   520, loss: 1.21960, precision: 0.938 recall: 0.918 f1: 0.928 accuracy: 0.991 
training batch:   540, loss: 1.58668, precision: 0.900 recall: 0.923 f1: 0.911 accuracy: 0.988 
training batch:   560, loss: 0.55902, precision: 0.971 recall: 0.944 f1: 0.958 accuracy: 0.993 
training batch:   580, loss: 1.37696, precision: 0.920 recall: 0.885 f1: 0.902 accuracy: 0.989 
training batch:   600, loss: 0.32872, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.999 
training batch:   620, loss: 1.36948, precision: 0.906 recall: 0.784 f1: 0.841 accuracy: 0.984 
training batch:   640, loss: 0.78299, precision: 0.970 recall: 0.929 f1: 0.949 accuracy: 0.993 
training batch:   660, loss: 0.76855, precision: 0.958 recall: 0.885 f1: 0.920 accuracy: 0.994 
training batch:   680, loss: 1.42080, precision: 0.911 recall: 0.932 f1: 0.921 accuracy: 0.982 
training batch:   700, loss: 0.27326, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 1.76816, precision: 0.933 recall: 0.889 f1: 0.911 accuracy: 0.985 
start evaluate engines...
label: ORG, precision: 0.877 recall: 0.834 f1: 0.849 accuracy: 0.000 
label: PER, precision: 0.960 recall: 0.954 f1: 0.954 accuracy: 0.000 
label: LOC, precision: 0.896 recall: 0.929 f1: 0.908 accuracy: 0.000 
time consumption:82.88(min), precision: 0.931 recall: 0.928 f1: 0.929 accuracy: 0.991 
saved the new best model with f1: 0.929
epoch:4/300
training batch:    20, loss: 1.08198, precision: 0.952 recall: 0.952 f1: 0.952 accuracy: 0.992 
training batch:    40, loss: 0.94104, precision: 0.912 recall: 0.867 f1: 0.889 accuracy: 0.994 
training batch:    60, loss: 0.84371, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.990 
training batch:    80, loss: 0.30065, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   100, loss: 0.18282, precision: 1.000 recall: 0.962 f1: 0.980 accuracy: 0.998 
training batch:   120, loss: 0.62518, precision: 0.969 recall: 0.940 f1: 0.955 accuracy: 0.994 
training batch:   140, loss: 0.88155, precision: 0.872 recall: 0.919 f1: 0.895 accuracy: 0.993 
training batch:   160, loss: 0.93425, precision: 0.938 recall: 0.900 f1: 0.918 accuracy: 0.992 
training batch:   180, loss: 0.53206, precision: 0.925 recall: 0.974 f1: 0.949 accuracy: 0.996 
training batch:   200, loss: 0.46646, precision: 1.000 recall: 0.963 f1: 0.981 accuracy: 0.996 
training batch:   220, loss: 0.54207, precision: 0.982 recall: 0.966 f1: 0.974 accuracy: 0.991 
training batch:   240, loss: 1.10541, precision: 0.926 recall: 0.980 f1: 0.952 accuracy: 0.989 
training batch:   260, loss: 0.51373, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.992 
training batch:   280, loss: 0.53559, precision: 0.962 recall: 0.944 f1: 0.953 accuracy: 0.991 
training batch:   300, loss: 0.50225, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.990 
training batch:   320, loss: 0.42742, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   340, loss: 0.53901, precision: 0.913 recall: 0.977 f1: 0.944 accuracy: 0.990 
training batch:   360, loss: 0.44025, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.995 
training batch:   380, loss: 1.17684, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.991 
training batch:   400, loss: 0.64916, precision: 0.919 recall: 0.905 f1: 0.912 accuracy: 0.992 
training batch:   420, loss: 1.33253, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.995 
training batch:   440, loss: 0.72782, precision: 0.978 recall: 0.936 f1: 0.957 accuracy: 0.991 
training batch:   460, loss: 0.51042, precision: 0.911 recall: 0.953 f1: 0.932 accuracy: 0.993 
training batch:   480, loss: 0.78822, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.988 
training batch:   500, loss: 0.88272, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.988 
training batch:   520, loss: 0.93511, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.988 
training batch:   540, loss: 0.66903, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.994 
training batch:   560, loss: 0.52262, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.992 
training batch:   580, loss: 0.62971, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.991 
training batch:   600, loss: 0.54736, precision: 0.951 recall: 0.975 f1: 0.963 accuracy: 0.990 
training batch:   620, loss: 1.03656, precision: 0.962 recall: 0.927 f1: 0.944 accuracy: 0.982 
training batch:   640, loss: 0.50136, precision: 0.929 recall: 0.945 f1: 0.937 accuracy: 0.993 
training batch:   660, loss: 0.36976, precision: 0.947 recall: 0.923 f1: 0.935 accuracy: 0.995 
training batch:   680, loss: 0.73808, precision: 0.930 recall: 0.898 f1: 0.914 accuracy: 0.990 
training batch:   700, loss: 0.11617, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 1.33152, precision: 0.927 recall: 0.864 f1: 0.894 accuracy: 0.990 
start evaluate engines...
label: ORG, precision: 0.880 recall: 0.840 f1: 0.853 accuracy: 0.000 
label: PER, precision: 0.959 recall: 0.964 f1: 0.959 accuracy: 0.000 
label: LOC, precision: 0.904 recall: 0.930 f1: 0.913 accuracy: 0.000 
time consumption:82.78(min), precision: 0.936 recall: 0.934 f1: 0.934 accuracy: 0.991 
saved the new best model with f1: 0.934
epoch:5/300
training batch:    20, loss: 0.66144, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.992 
training batch:    40, loss: 0.40385, precision: 0.933 recall: 0.949 f1: 0.941 accuracy: 0.996 
training batch:    60, loss: 0.34042, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.998 
training batch:    80, loss: 0.27410, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.997 
training batch:   100, loss: 0.24086, precision: 0.959 recall: 0.959 f1: 0.959 accuracy: 0.997 
training batch:   120, loss: 0.10668, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.48461, precision: 0.909 recall: 0.943 f1: 0.926 accuracy: 0.989 
training batch:   160, loss: 0.26793, precision: 0.974 recall: 1.000 f1: 0.987 accuracy: 0.999 
training batch:   180, loss: 0.43431, precision: 0.952 recall: 0.968 f1: 0.960 accuracy: 0.998 
training batch:   200, loss: 0.84632, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.987 
training batch:   220, loss: 0.24998, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   240, loss: 0.45589, precision: 0.977 recall: 0.935 f1: 0.956 accuracy: 0.997 
training batch:   260, loss: 0.44474, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.994 
training batch:   280, loss: 0.82109, precision: 0.926 recall: 0.877 f1: 0.901 accuracy: 0.992 
training batch:   300, loss: 0.59185, precision: 0.889 recall: 0.889 f1: 0.889 accuracy: 0.994 
training batch:   320, loss: 0.50743, precision: 0.979 recall: 0.920 f1: 0.948 accuracy: 0.997 
training batch:   340, loss: 0.77378, precision: 0.884 recall: 0.927 f1: 0.905 accuracy: 0.986 
training batch:   360, loss: 0.30760, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.997 
training batch:   380, loss: 1.03711, precision: 0.943 recall: 0.926 f1: 0.935 accuracy: 0.988 
training batch:   400, loss: 0.25636, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.997 
training batch:   420, loss: 0.39586, precision: 0.912 recall: 0.939 f1: 0.925 accuracy: 0.993 
training batch:   440, loss: 0.38123, precision: 0.930 recall: 0.976 f1: 0.952 accuracy: 0.996 
training batch:   460, loss: 0.97151, precision: 0.930 recall: 0.892 f1: 0.910 accuracy: 0.986 
training batch:   480, loss: 0.36892, precision: 0.981 recall: 0.964 f1: 0.972 accuracy: 0.996 
training batch:   500, loss: 0.64796, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.988 
training batch:   520, loss: 1.69429, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.975 
training batch:   540, loss: 0.31659, precision: 0.970 recall: 0.941 f1: 0.955 accuracy: 0.995 
training batch:   560, loss: 2.07663, precision: 0.869 recall: 0.815 f1: 0.841 accuracy: 0.972 
training batch:   580, loss: 0.86805, precision: 0.967 recall: 0.921 f1: 0.943 accuracy: 0.984 
training batch:   600, loss: 0.20056, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.49084, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.996 
training batch:   640, loss: 0.32630, precision: 0.946 recall: 0.921 f1: 0.933 accuracy: 0.997 
training batch:   660, loss: 0.31257, precision: 0.982 recall: 1.000 f1: 0.991 accuracy: 0.996 
training batch:   680, loss: 0.48199, precision: 0.957 recall: 0.917 f1: 0.936 accuracy: 0.995 
training batch:   700, loss: 0.41617, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.996 
training batch:   720, loss: 0.52075, precision: 0.911 recall: 0.911 f1: 0.911 accuracy: 0.992 
start evaluate engines...
label: ORG, precision: 0.878 recall: 0.879 f1: 0.875 accuracy: 0.000 
label: PER, precision: 0.971 recall: 0.969 f1: 0.968 accuracy: 0.000 
label: LOC, precision: 0.921 recall: 0.930 f1: 0.923 accuracy: 0.000 
time consumption:84.59(min), precision: 0.938 recall: 0.939 f1: 0.938 accuracy: 0.992 
saved the new best model with f1: 0.938
epoch:6/300
training batch:    20, loss: 0.47650, precision: 0.870 recall: 0.904 f1: 0.887 accuracy: 0.992 
training batch:    40, loss: 0.49602, precision: 1.000 recall: 0.929 f1: 0.963 accuracy: 0.994 
training batch:    60, loss: 1.14265, precision: 0.898 recall: 0.863 f1: 0.880 accuracy: 0.986 
training batch:    80, loss: 0.44774, precision: 0.915 recall: 0.964 f1: 0.939 accuracy: 0.992 
training batch:   100, loss: 0.50689, precision: 0.957 recall: 0.938 f1: 0.947 accuracy: 0.991 
training batch:   120, loss: 0.29955, precision: 0.889 recall: 0.941 f1: 0.914 accuracy: 0.995 
training batch:   140, loss: 0.22377, precision: 0.980 recall: 0.962 f1: 0.971 accuracy: 0.998 
training batch:   160, loss: 0.20847, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.996 
training batch:   180, loss: 0.10499, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   200, loss: 0.32484, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.995 
training batch:   220, loss: 0.57768, precision: 0.937 recall: 0.967 f1: 0.952 accuracy: 0.989 
training batch:   240, loss: 0.24725, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.999 
training batch:   260, loss: 0.71671, precision: 0.973 recall: 0.973 f1: 0.973 accuracy: 0.992 
training batch:   280, loss: 0.36096, precision: 0.939 recall: 0.979 f1: 0.958 accuracy: 0.996 
training batch:   300, loss: 0.42373, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   320, loss: 0.41614, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.995 
training batch:   340, loss: 0.24615, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.996 
training batch:   360, loss: 0.72127, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.994 
training batch:   380, loss: 0.46218, precision: 0.903 recall: 0.933 f1: 0.918 accuracy: 0.991 
training batch:   400, loss: 0.52955, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.990 
training batch:   420, loss: 0.20559, precision: 0.960 recall: 0.923 f1: 0.941 accuracy: 0.997 
training batch:   440, loss: 0.49177, precision: 0.955 recall: 1.000 f1: 0.977 accuracy: 0.994 
training batch:   460, loss: 0.66477, precision: 0.920 recall: 0.979 f1: 0.948 accuracy: 0.994 
training batch:   480, loss: 0.41543, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.996 
training batch:   500, loss: 0.40835, precision: 0.963 recall: 0.912 f1: 0.937 accuracy: 0.995 
training batch:   520, loss: 0.41516, precision: 0.824 recall: 0.875 f1: 0.848 accuracy: 0.989 
training batch:   540, loss: 0.33564, precision: 0.966 recall: 0.982 f1: 0.974 accuracy: 0.996 
training batch:   560, loss: 0.27557, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   580, loss: 0.39126, precision: 0.915 recall: 0.935 f1: 0.925 accuracy: 0.995 
training batch:   600, loss: 0.20394, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.998 
training batch:   620, loss: 0.53298, precision: 0.953 recall: 0.932 f1: 0.943 accuracy: 0.996 
training batch:   640, loss: 0.76617, precision: 0.962 recall: 0.981 f1: 0.971 accuracy: 0.991 
training batch:   660, loss: 0.30047, precision: 0.982 recall: 0.947 f1: 0.964 accuracy: 0.998 
training batch:   680, loss: 0.62215, precision: 0.907 recall: 0.980 f1: 0.942 accuracy: 0.988 
training batch:   700, loss: 0.21674, precision: 0.980 recall: 1.000 f1: 0.990 accuracy: 0.999 
training batch:   720, loss: 0.87365, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.990 
start evaluate engines...
label: ORG, precision: 0.898 recall: 0.883 f1: 0.886 accuracy: 0.000 
label: PER, precision: 0.975 recall: 0.970 f1: 0.971 accuracy: 0.000 
label: LOC, precision: 0.938 recall: 0.936 f1: 0.935 accuracy: 0.000 
time consumption:83.13(min), precision: 0.952 recall: 0.941 f1: 0.946 accuracy: 0.993 
saved the new best model with f1: 0.946
epoch:7/300
training batch:    20, loss: 0.09768, precision: 0.967 recall: 1.000 f1: 0.983 accuracy: 0.995 
training batch:    40, loss: 0.16533, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:    60, loss: 0.21849, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.993 
training batch:    80, loss: 0.58134, precision: 0.930 recall: 0.930 f1: 0.930 accuracy: 0.992 
training batch:   100, loss: 0.90481, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.990 
training batch:   120, loss: 0.12712, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.999 
training batch:   140, loss: 0.09776, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:   160, loss: 0.27534, precision: 0.983 recall: 0.967 f1: 0.975 accuracy: 0.999 
training batch:   180, loss: 0.51060, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.997 
training batch:   200, loss: 0.61751, precision: 0.921 recall: 0.897 f1: 0.909 accuracy: 0.984 
training batch:   220, loss: 0.14038, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.997 
training batch:   240, loss: 0.47763, precision: 0.966 recall: 0.933 f1: 0.949 accuracy: 0.991 
training batch:   260, loss: 0.10481, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:   280, loss: 0.23016, precision: 0.986 recall: 0.986 f1: 0.986 accuracy: 0.998 
training batch:   300, loss: 0.34392, precision: 0.943 recall: 0.917 f1: 0.930 accuracy: 0.992 
training batch:   320, loss: 0.49582, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.995 
training batch:   340, loss: 0.11679, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.999 
training batch:   360, loss: 0.52895, precision: 0.933 recall: 0.933 f1: 0.933 accuracy: 0.997 
training batch:   380, loss: 0.94821, precision: 1.000 recall: 0.985 f1: 0.992 accuracy: 0.991 
training batch:   400, loss: 0.30986, precision: 0.958 recall: 0.958 f1: 0.958 accuracy: 0.996 
training batch:   420, loss: 0.38618, precision: 0.980 recall: 0.980 f1: 0.980 accuracy: 0.994 
training batch:   440, loss: 0.40276, precision: 0.986 recall: 0.958 f1: 0.971 accuracy: 0.994 
training batch:   460, loss: 0.62990, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.990 
training batch:   480, loss: 0.39636, precision: 0.974 recall: 0.962 f1: 0.968 accuracy: 0.995 
training batch:   500, loss: 0.20445, precision: 0.982 recall: 0.964 f1: 0.973 accuracy: 0.998 
training batch:   520, loss: 0.53654, precision: 1.000 recall: 0.953 f1: 0.976 accuracy: 0.996 
training batch:   540, loss: 0.37847, precision: 1.000 recall: 0.964 f1: 0.981 accuracy: 0.999 
training batch:   560, loss: 0.59964, precision: 0.918 recall: 0.957 f1: 0.938 accuracy: 0.994 
training batch:   580, loss: 0.42194, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.991 
training batch:   600, loss: 0.12461, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.998 
training batch:   620, loss: 0.43685, precision: 1.000 recall: 0.981 f1: 0.990 accuracy: 0.993 
training batch:   640, loss: 0.43044, precision: 0.953 recall: 0.953 f1: 0.953 accuracy: 0.993 
training batch:   660, loss: 0.24046, precision: 0.980 recall: 0.980 f1: 0.980 accuracy: 0.999 
training batch:   680, loss: 0.28971, precision: 0.985 recall: 0.985 f1: 0.985 accuracy: 0.998 
training batch:   700, loss: 0.78748, precision: 0.938 recall: 0.910 f1: 0.924 accuracy: 0.983 
training batch:   720, loss: 0.28219, precision: 0.979 recall: 0.959 f1: 0.969 accuracy: 0.995 
start evaluate engines...
label: ORG, precision: 0.894 recall: 0.878 f1: 0.881 accuracy: 0.000 
label: PER, precision: 0.972 recall: 0.964 f1: 0.965 accuracy: 0.000 
label: LOC, precision: 0.927 recall: 0.939 f1: 0.930 accuracy: 0.000 
time consumption:82.13(min), precision: 0.946 recall: 0.941 f1: 0.943 accuracy: 0.993 
epoch:8/300
training batch:    20, loss: 0.32121, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.990 
training batch:    40, loss: 0.53476, precision: 0.964 recall: 0.930 f1: 0.946 accuracy: 0.992 
training batch:    60, loss: 0.55390, precision: 0.935 recall: 0.915 f1: 0.925 accuracy: 0.994 
training batch:    80, loss: 0.50899, precision: 0.915 recall: 0.878 f1: 0.896 accuracy: 0.987 
training batch:   100, loss: 0.08266, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   120, loss: 0.21159, precision: 0.984 recall: 1.000 f1: 0.992 accuracy: 0.998 
training batch:   140, loss: 0.19537, precision: 0.980 recall: 0.980 f1: 0.980 accuracy: 0.997 
training batch:   160, loss: 0.15568, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.998 
training batch:   180, loss: 0.49536, precision: 0.987 recall: 0.961 f1: 0.974 accuracy: 0.990 
training batch:   200, loss: 0.15926, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   220, loss: 0.33761, precision: 0.947 recall: 1.000 f1: 0.973 accuracy: 0.987 
training batch:   240, loss: 0.24214, precision: 0.984 recall: 0.984 f1: 0.984 accuracy: 0.997 
training batch:   260, loss: 0.22721, precision: 0.984 recall: 0.984 f1: 0.984 accuracy: 0.999 
training batch:   280, loss: 0.63159, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.996 
training batch:   300, loss: 0.45032, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.992 
training batch:   320, loss: 0.88246, precision: 0.958 recall: 0.945 f1: 0.952 accuracy: 0.993 
training batch:   340, loss: 0.48250, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.994 
training batch:   360, loss: 0.13400, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   380, loss: 0.08451, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   400, loss: 0.34035, precision: 1.000 recall: 0.965 f1: 0.982 accuracy: 0.994 
training batch:   420, loss: 0.51133, precision: 0.917 recall: 0.936 f1: 0.926 accuracy: 0.992 
training batch:   440, loss: 0.10116, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   460, loss: 0.51451, precision: 0.906 recall: 0.960 f1: 0.932 accuracy: 0.991 
training batch:   480, loss: 0.73240, precision: 0.879 recall: 0.921 f1: 0.899 accuracy: 0.987 
training batch:   500, loss: 0.06340, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.45068, precision: 0.887 recall: 0.870 f1: 0.879 accuracy: 0.992 
training batch:   540, loss: 0.18933, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.997 
training batch:   560, loss: 0.28026, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.997 
training batch:   580, loss: 0.32415, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.995 
training batch:   600, loss: 0.22100, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.997 
training batch:   620, loss: 0.21206, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.999 
training batch:   640, loss: 0.25152, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.995 
training batch:   660, loss: 0.57288, precision: 0.930 recall: 0.889 f1: 0.909 accuracy: 0.979 
training batch:   680, loss: 0.24881, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.997 
training batch:   700, loss: 0.36003, precision: 0.973 recall: 0.923 f1: 0.947 accuracy: 0.990 
training batch:   720, loss: 0.30997, precision: 0.944 recall: 0.971 f1: 0.958 accuracy: 0.995 
start evaluate engines...
label: ORG, precision: 0.866 recall: 0.896 f1: 0.876 accuracy: 0.000 
label: PER, precision: 0.968 recall: 0.972 f1: 0.967 accuracy: 0.000 
label: LOC, precision: 0.936 recall: 0.930 f1: 0.931 accuracy: 0.000 
time consumption:82.72(min), precision: 0.940 recall: 0.944 f1: 0.941 accuracy: 0.992 
epoch:9/300
training batch:    20, loss: 0.18813, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    40, loss: 0.12462, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:    60, loss: 0.24423, precision: 0.949 recall: 0.949 f1: 0.949 accuracy: 0.997 
training batch:    80, loss: 0.12089, precision: 0.984 recall: 0.984 f1: 0.984 accuracy: 0.999 
training batch:   100, loss: 0.11002, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.999 
training batch:   120, loss: 0.22893, precision: 0.951 recall: 0.907 f1: 0.929 accuracy: 0.996 
training batch:   140, loss: 0.18824, precision: 0.976 recall: 1.000 f1: 0.988 accuracy: 0.992 
training batch:   160, loss: 0.59759, precision: 0.943 recall: 0.957 f1: 0.950 accuracy: 0.991 
training batch:   180, loss: 0.27226, precision: 0.983 recall: 0.950 f1: 0.966 accuracy: 0.996 
training batch:   200, loss: 0.48105, precision: 0.943 recall: 0.943 f1: 0.943 accuracy: 0.991 
training batch:   220, loss: 0.09679, precision: 1.000 recall: 0.976 f1: 0.988 accuracy: 0.998 
training batch:   240, loss: 0.18181, precision: 0.962 recall: 0.962 f1: 0.962 accuracy: 0.997 
training batch:   260, loss: 0.40787, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.992 
training batch:   280, loss: 0.73929, precision: 0.911 recall: 0.911 f1: 0.911 accuracy: 0.990 
training batch:   300, loss: 0.33604, precision: 0.963 recall: 0.897 f1: 0.929 accuracy: 0.992 
training batch:   320, loss: 0.31977, precision: 0.982 recall: 0.949 f1: 0.966 accuracy: 0.996 
training batch:   340, loss: 0.26163, precision: 1.000 recall: 0.967 f1: 0.983 accuracy: 0.996 
training batch:   360, loss: 0.48780, precision: 0.988 recall: 0.988 f1: 0.988 accuracy: 0.998 
training batch:   380, loss: 0.24177, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.999 
training batch:   400, loss: 0.22776, precision: 0.971 recall: 1.000 f1: 0.986 accuracy: 0.996 
training batch:   420, loss: 0.22131, precision: 0.965 recall: 0.965 f1: 0.965 accuracy: 0.997 
training batch:   440, loss: 0.31567, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.995 
training batch:   460, loss: 0.43259, precision: 0.907 recall: 0.951 f1: 0.929 accuracy: 0.993 
training batch:   480, loss: 0.19730, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.998 
training batch:   500, loss: 0.20302, precision: 0.981 recall: 0.963 f1: 0.972 accuracy: 0.998 
training batch:   520, loss: 0.14402, precision: 0.980 recall: 1.000 f1: 0.990 accuracy: 0.996 
training batch:   540, loss: 0.31638, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.997 
training batch:   560, loss: 0.45334, precision: 0.977 recall: 0.933 f1: 0.955 accuracy: 0.993 
training batch:   580, loss: 0.16062, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.998 
training batch:   600, loss: 0.16687, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   620, loss: 0.60446, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.993 
training batch:   640, loss: 0.23118, precision: 0.939 recall: 0.969 f1: 0.954 accuracy: 0.998 
training batch:   660, loss: 0.58182, precision: 0.940 recall: 0.963 f1: 0.952 accuracy: 0.990 
training batch:   680, loss: 0.58535, precision: 0.940 recall: 1.000 f1: 0.969 accuracy: 0.997 
training batch:   700, loss: 0.49311, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.992 
training batch:   720, loss: 0.11921, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: ORG, precision: 0.872 recall: 0.893 f1: 0.878 accuracy: 0.000 
label: PER, precision: 0.964 recall: 0.973 f1: 0.966 accuracy: 0.000 
label: LOC, precision: 0.945 recall: 0.924 f1: 0.932 accuracy: 0.000 
time consumption:83.81(min), precision: 0.942 recall: 0.940 f1: 0.941 accuracy: 0.992 
epoch:10/300
training batch:    20, loss: 0.18507, precision: 0.955 recall: 0.977 f1: 0.966 accuracy: 0.997 
training batch:    40, loss: 0.11237, precision: 0.986 recall: 0.986 f1: 0.986 accuracy: 0.999 
training batch:    60, loss: 0.38717, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.997 
training batch:    80, loss: 0.18765, precision: 1.000 recall: 0.947 f1: 0.973 accuracy: 0.996 
training batch:   100, loss: 0.21678, precision: 1.000 recall: 0.956 f1: 0.977 accuracy: 0.995 
training batch:   120, loss: 0.11091, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   140, loss: 0.17806, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.998 
training batch:   160, loss: 0.29640, precision: 0.982 recall: 0.982 f1: 0.982 accuracy: 0.997 
training batch:   180, loss: 0.34106, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.998 
training batch:   200, loss: 0.18811, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:   220, loss: 0.23809, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.994 
training batch:   240, loss: 0.28975, precision: 0.967 recall: 0.937 f1: 0.952 accuracy: 0.993 
training batch:   260, loss: 0.14492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   280, loss: 0.16933, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.999 
training batch:   300, loss: 0.21523, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   320, loss: 0.21056, precision: 0.980 recall: 1.000 f1: 0.990 accuracy: 0.996 
training batch:   340, loss: 0.25830, precision: 0.982 recall: 0.982 f1: 0.982 accuracy: 0.995 
training batch:   360, loss: 0.23571, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.994 
training batch:   380, loss: 0.38330, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.999 
training batch:   400, loss: 0.12804, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.14654, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.997 
training batch:   440, loss: 0.10583, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.999 
training batch:   460, loss: 0.73454, precision: 1.000 recall: 0.956 f1: 0.977 accuracy: 0.993 
training batch:   480, loss: 0.50103, precision: 0.923 recall: 0.968 f1: 0.945 accuracy: 0.989 
training batch:   500, loss: 0.02047, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   520, loss: 0.26341, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.993 
training batch:   540, loss: 0.22349, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.995 
training batch:   560, loss: 0.30378, precision: 0.948 recall: 0.965 f1: 0.957 accuracy: 0.996 
training batch:   580, loss: 0.14488, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.999 
training batch:   600, loss: 0.40148, precision: 0.958 recall: 0.939 f1: 0.948 accuracy: 0.996 
training batch:   620, loss: 0.22603, precision: 1.000 recall: 0.966 f1: 0.982 accuracy: 0.999 
training batch:   640, loss: 0.33313, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.995 
training batch:   660, loss: 0.21998, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.998 
training batch:   680, loss: 0.17948, precision: 0.986 recall: 0.986 f1: 0.986 accuracy: 0.995 
training batch:   700, loss: 0.32754, precision: 0.968 recall: 0.968 f1: 0.968 accuracy: 0.996 
training batch:   720, loss: 0.37428, precision: 0.962 recall: 0.926 f1: 0.943 accuracy: 0.993 
start evaluate engines...
label: ORG, precision: 0.898 recall: 0.882 f1: 0.886 accuracy: 0.000 
label: PER, precision: 0.968 recall: 0.975 f1: 0.968 accuracy: 0.000 
label: LOC, precision: 0.931 recall: 0.932 f1: 0.929 accuracy: 0.000 
time consumption:82.86(min), precision: 0.948 recall: 0.945 f1: 0.946 accuracy: 0.993 
saved the new best model with f1: 0.946
epoch:11/300
training batch:    20, loss: 0.19332, precision: 0.986 recall: 1.000 f1: 0.993 accuracy: 0.998 
training batch:    40, loss: 0.15776, precision: 1.000 recall: 0.975 f1: 0.987 accuracy: 0.999 
training batch:    60, loss: 0.15721, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.999 
