2020-09-13 09:08:00
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets
     train            file: train.csv
     validation       file: dev.csv
     vocab             dir: data/example_datasets/vocabs
     delimiter            : b
     use              bert: False
     checkpoints       dir: checkpoints/datasets_bilsm-crf
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['ORG', 'PER', 'LOC']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 300
     max  sequence  length: 300
     hidden            dim: 200
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 42
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 300
     batch            size: 32
     dropout              : 0.5
     learning         rate: 0.001
     optimizer            : Adam
     checkpoint       name: model
     max       checkpoints: 3
     print       per_batch: 20
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
loading vocab...
dataManager initialed...
mode: train
loading data...
loading data...
training set size: 23181, validating set size: 4636
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/300
training batch:    20, loss: 29.30713, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.874 
training batch:    40, loss: 25.55204, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.888 
training batch:    60, loss: 15.64107, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.904 
training batch:    80, loss: 15.97099, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.889 
training batch:   100, loss: 17.70255, precision: 1.000 recall: 0.018 f1: 0.035 accuracy: 0.884 
training batch:   120, loss: 12.47717, precision: 0.421 recall: 0.167 f1: 0.239 accuracy: 0.908 
training batch:   140, loss: 9.59134, precision: 0.667 recall: 0.136 f1: 0.226 accuracy: 0.918 
training batch:   160, loss: 12.74881, precision: 0.400 recall: 0.127 f1: 0.193 accuracy: 0.915 
training batch:   180, loss: 11.90854, precision: 0.233 recall: 0.119 f1: 0.157 accuracy: 0.899 
training batch:   200, loss: 11.68063, precision: 0.488 recall: 0.351 f1: 0.408 accuracy: 0.929 
training batch:   220, loss: 9.36077, precision: 0.429 recall: 0.279 f1: 0.338 accuracy: 0.919 
training batch:   240, loss: 6.85205, precision: 0.606 recall: 0.392 f1: 0.476 accuracy: 0.942 
training batch:   260, loss: 6.90697, precision: 0.483 recall: 0.368 f1: 0.418 accuracy: 0.951 
training batch:   280, loss: 8.69045, precision: 0.529 recall: 0.353 f1: 0.424 accuracy: 0.910 
training batch:   300, loss: 4.82424, precision: 0.600 recall: 0.375 f1: 0.462 accuracy: 0.963 
training batch:   320, loss: 7.54944, precision: 0.636 recall: 0.438 f1: 0.519 accuracy: 0.950 
training batch:   340, loss: 6.01430, precision: 0.571 recall: 0.522 f1: 0.545 accuracy: 0.956 
training batch:   360, loss: 7.02673, precision: 0.643 recall: 0.509 f1: 0.568 accuracy: 0.940 
training batch:   380, loss: 9.14693, precision: 0.614 recall: 0.409 f1: 0.491 accuracy: 0.928 
training batch:   400, loss: 9.42164, precision: 0.553 recall: 0.441 f1: 0.491 accuracy: 0.919 
training batch:   420, loss: 7.18826, precision: 0.600 recall: 0.474 f1: 0.529 accuracy: 0.942 
training batch:   440, loss: 7.40545, precision: 0.542 recall: 0.491 f1: 0.515 accuracy: 0.944 
training batch:   460, loss: 7.40911, precision: 0.698 recall: 0.607 f1: 0.649 accuracy: 0.926 
training batch:   480, loss: 5.96336, precision: 0.711 recall: 0.582 f1: 0.640 accuracy: 0.945 
training batch:   500, loss: 7.42675, precision: 0.733 recall: 0.638 f1: 0.682 accuracy: 0.959 
training batch:   520, loss: 7.68490, precision: 0.582 recall: 0.542 f1: 0.561 accuracy: 0.936 
training batch:   540, loss: 6.52191, precision: 0.686 recall: 0.648 f1: 0.667 accuracy: 0.944 
training batch:   560, loss: 6.09631, precision: 0.600 recall: 0.659 f1: 0.628 accuracy: 0.946 
training batch:   580, loss: 7.80646, precision: 0.730 recall: 0.667 f1: 0.697 accuracy: 0.943 
training batch:   600, loss: 5.38724, precision: 0.632 recall: 0.545 f1: 0.585 accuracy: 0.960 
training batch:   620, loss: 3.80895, precision: 0.605 recall: 0.548 f1: 0.575 accuracy: 0.955 
training batch:   640, loss: 5.55569, precision: 0.780 recall: 0.571 f1: 0.660 accuracy: 0.952 
training batch:   660, loss: 4.60314, precision: 0.741 recall: 0.571 f1: 0.645 accuracy: 0.960 
training batch:   680, loss: 4.66391, precision: 0.635 recall: 0.589 f1: 0.611 accuracy: 0.959 
training batch:   700, loss: 6.33285, precision: 0.684 recall: 0.510 f1: 0.584 accuracy: 0.953 
training batch:   720, loss: 3.37100, precision: 0.667 recall: 0.615 f1: 0.640 accuracy: 0.970 
start evaluate engines...
label: ORG, precision: 0.590 recall: 0.464 f1: 0.503 accuracy: 0.000 
label: PER, precision: 0.790 recall: 0.631 f1: 0.689 accuracy: 0.000 
label: LOC, precision: 0.564 recall: 0.620 f1: 0.583 accuracy: 0.000 
time consumption:6.97(min), precision: 0.666 recall: 0.612 f1: 0.635 accuracy: 0.960 
saved the new best model with f1: 0.635
epoch:2/300
training batch:    20, loss: 7.12100, precision: 0.682 recall: 0.625 f1: 0.652 accuracy: 0.949 
training batch:    40, loss: 4.66428, precision: 0.643 recall: 0.509 f1: 0.568 accuracy: 0.959 
training batch:    60, loss: 3.61090, precision: 0.707 recall: 0.617 f1: 0.659 accuracy: 0.969 
training batch:    80, loss: 3.32532, precision: 0.718 recall: 0.622 f1: 0.667 accuracy: 0.958 
training batch:   100, loss: 5.83929, precision: 0.761 recall: 0.700 f1: 0.729 accuracy: 0.954 
training batch:   120, loss: 3.51967, precision: 0.722 recall: 0.736 f1: 0.729 accuracy: 0.968 
training batch:   140, loss: 3.45400, precision: 0.641 recall: 0.568 f1: 0.602 accuracy: 0.974 
training batch:   160, loss: 3.35401, precision: 0.686 recall: 0.686 f1: 0.686 accuracy: 0.970 
training batch:   180, loss: 4.34962, precision: 0.719 recall: 0.683 f1: 0.701 accuracy: 0.964 
training batch:   200, loss: 4.00327, precision: 0.639 recall: 0.535 f1: 0.582 accuracy: 0.959 
training batch:   220, loss: 4.17555, precision: 0.636 recall: 0.583 f1: 0.609 accuracy: 0.964 
training batch:   240, loss: 3.83329, precision: 0.718 recall: 0.683 f1: 0.700 accuracy: 0.956 
training batch:   260, loss: 3.47118, precision: 0.787 recall: 0.712 f1: 0.747 accuracy: 0.960 
training batch:   280, loss: 3.55658, precision: 0.800 recall: 0.667 f1: 0.727 accuracy: 0.963 
training batch:   300, loss: 2.79412, precision: 0.690 recall: 0.714 f1: 0.702 accuracy: 0.976 
training batch:   320, loss: 4.30613, precision: 0.656 recall: 0.600 f1: 0.627 accuracy: 0.957 
training batch:   340, loss: 3.01485, precision: 0.763 recall: 0.725 f1: 0.744 accuracy: 0.975 
training batch:   360, loss: 3.36396, precision: 0.738 recall: 0.674 f1: 0.705 accuracy: 0.954 
training batch:   380, loss: 3.79072, precision: 0.774 recall: 0.804 f1: 0.788 accuracy: 0.975 
training batch:   400, loss: 6.09524, precision: 0.726 recall: 0.703 f1: 0.714 accuracy: 0.950 
training batch:   420, loss: 2.77614, precision: 0.719 recall: 0.676 f1: 0.697 accuracy: 0.970 
training batch:   440, loss: 3.62216, precision: 0.897 recall: 0.745 f1: 0.814 accuracy: 0.967 
training batch:   460, loss: 2.62087, precision: 0.750 recall: 0.771 f1: 0.761 accuracy: 0.976 
training batch:   480, loss: 4.47360, precision: 0.787 recall: 0.649 f1: 0.712 accuracy: 0.956 
training batch:   500, loss: 2.87140, precision: 0.700 recall: 0.636 f1: 0.667 accuracy: 0.976 
training batch:   520, loss: 3.68184, precision: 0.780 recall: 0.754 f1: 0.767 accuracy: 0.964 
training batch:   540, loss: 2.86389, precision: 0.676 recall: 0.658 f1: 0.667 accuracy: 0.970 
training batch:   560, loss: 4.18752, precision: 0.731 recall: 0.679 f1: 0.704 accuracy: 0.966 
training batch:   580, loss: 4.06041, precision: 0.592 recall: 0.547 f1: 0.569 accuracy: 0.952 
training batch:   600, loss: 4.38614, precision: 0.779 recall: 0.804 f1: 0.791 accuracy: 0.962 
training batch:   620, loss: 3.23677, precision: 0.789 recall: 0.789 f1: 0.789 accuracy: 0.971 
training batch:   640, loss: 4.84514, precision: 0.795 recall: 0.608 f1: 0.689 accuracy: 0.963 
training batch:   660, loss: 3.30474, precision: 0.745 recall: 0.593 f1: 0.660 accuracy: 0.963 
training batch:   680, loss: 2.57741, precision: 0.732 recall: 0.652 f1: 0.690 accuracy: 0.975 
training batch:   700, loss: 2.31808, precision: 0.897 recall: 0.833 f1: 0.864 accuracy: 0.984 
training batch:   720, loss: 3.02218, precision: 0.840 recall: 0.808 f1: 0.824 accuracy: 0.967 
start evaluate engines...
label: ORG, precision: 0.602 recall: 0.663 f1: 0.618 accuracy: 0.000 
label: PER, precision: 0.827 recall: 0.768 f1: 0.787 accuracy: 0.000 
label: LOC, precision: 0.729 recall: 0.725 f1: 0.719 accuracy: 0.000 
time consumption:6.77(min), precision: 0.746 recall: 0.741 f1: 0.741 accuracy: 0.967 
saved the new best model with f1: 0.741
epoch:3/300
training batch:    20, loss: 5.56134, precision: 0.727 recall: 0.709 f1: 0.718 accuracy: 0.947 
training batch:    40, loss: 1.62021, precision: 0.805 recall: 0.786 f1: 0.795 accuracy: 0.987 
training batch:    60, loss: 3.20441, precision: 0.724 recall: 0.689 f1: 0.706 accuracy: 0.974 
training batch:    80, loss: 3.45356, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.970 
training batch:   100, loss: 2.96924, precision: 0.783 recall: 0.692 f1: 0.735 accuracy: 0.972 
training batch:   120, loss: 2.62448, precision: 0.841 recall: 0.712 f1: 0.771 accuracy: 0.969 
training batch:   140, loss: 2.04302, precision: 0.755 recall: 0.804 f1: 0.779 accuracy: 0.982 
training batch:   160, loss: 1.80845, precision: 0.821 recall: 0.676 f1: 0.742 accuracy: 0.972 
training batch:   180, loss: 2.53654, precision: 0.944 recall: 0.850 f1: 0.895 accuracy: 0.982 
training batch:   200, loss: 3.38886, precision: 0.814 recall: 0.738 f1: 0.774 accuracy: 0.970 
training batch:   220, loss: 2.88912, precision: 0.738 recall: 0.828 f1: 0.780 accuracy: 0.965 
training batch:   240, loss: 2.90057, precision: 0.658 recall: 0.641 f1: 0.649 accuracy: 0.969 
training batch:   260, loss: 4.01122, precision: 0.849 recall: 0.703 f1: 0.769 accuracy: 0.966 
training batch:   280, loss: 2.19705, precision: 0.873 recall: 0.842 f1: 0.857 accuracy: 0.978 
training batch:   300, loss: 2.99000, precision: 0.727 recall: 0.632 f1: 0.676 accuracy: 0.968 
training batch:   320, loss: 2.41956, precision: 0.769 recall: 0.714 f1: 0.741 accuracy: 0.964 
training batch:   340, loss: 4.18541, precision: 0.755 recall: 0.678 f1: 0.714 accuracy: 0.960 
training batch:   360, loss: 2.36602, precision: 0.803 recall: 0.790 f1: 0.797 accuracy: 0.968 
training batch:   380, loss: 1.93689, precision: 0.809 recall: 0.826 f1: 0.817 accuracy: 0.972 
training batch:   400, loss: 3.38839, precision: 0.873 recall: 0.774 f1: 0.821 accuracy: 0.967 
training batch:   420, loss: 2.51130, precision: 0.827 recall: 0.741 f1: 0.782 accuracy: 0.974 
training batch:   440, loss: 1.65698, precision: 0.878 recall: 0.766 f1: 0.818 accuracy: 0.980 
training batch:   460, loss: 2.45166, precision: 0.778 recall: 0.714 f1: 0.745 accuracy: 0.966 
training batch:   480, loss: 2.62422, precision: 0.838 recall: 0.848 f1: 0.843 accuracy: 0.979 
training batch:   500, loss: 3.73391, precision: 0.735 recall: 0.692 f1: 0.713 accuracy: 0.962 
training batch:   520, loss: 2.12040, precision: 0.744 recall: 0.762 f1: 0.753 accuracy: 0.980 
training batch:   540, loss: 1.95457, precision: 0.938 recall: 0.811 f1: 0.870 accuracy: 0.984 
training batch:   560, loss: 1.87663, precision: 0.852 recall: 0.719 f1: 0.780 accuracy: 0.974 
training batch:   580, loss: 1.47421, precision: 0.894 recall: 0.857 f1: 0.875 accuracy: 0.985 
training batch:   600, loss: 1.70674, precision: 0.881 recall: 0.860 f1: 0.871 accuracy: 0.986 
training batch:   620, loss: 2.39252, precision: 0.920 recall: 0.676 f1: 0.780 accuracy: 0.974 
training batch:   640, loss: 2.54874, precision: 0.803 recall: 0.791 f1: 0.797 accuracy: 0.967 
training batch:   660, loss: 2.17330, precision: 0.886 recall: 0.796 f1: 0.839 accuracy: 0.981 
training batch:   680, loss: 2.19720, precision: 0.756 recall: 0.829 f1: 0.791 accuracy: 0.968 
training batch:   700, loss: 0.89104, precision: 0.900 recall: 0.947 f1: 0.923 accuracy: 0.993 
training batch:   720, loss: 3.41513, precision: 0.824 recall: 0.750 f1: 0.785 accuracy: 0.955 
start evaluate engines...
label: ORG, precision: 0.763 recall: 0.671 f1: 0.702 accuracy: 0.000 
label: PER, precision: 0.870 recall: 0.800 f1: 0.825 accuracy: 0.000 
label: LOC, precision: 0.767 recall: 0.811 f1: 0.781 accuracy: 0.000 
time consumption:6.75(min), precision: 0.820 recall: 0.790 f1: 0.803 accuracy: 0.975 
saved the new best model with f1: 0.803
epoch:4/300
training batch:    20, loss: 3.27191, precision: 0.849 recall: 0.763 f1: 0.804 accuracy: 0.962 
training batch:    40, loss: 2.57183, precision: 0.789 recall: 0.789 f1: 0.789 accuracy: 0.974 
training batch:    60, loss: 2.37820, precision: 0.793 recall: 0.767 f1: 0.780 accuracy: 0.972 
training batch:    80, loss: 1.50395, precision: 0.881 recall: 0.902 f1: 0.892 accuracy: 0.984 
training batch:   100, loss: 0.49547, precision: 0.885 recall: 0.920 f1: 0.902 accuracy: 0.990 
training batch:   120, loss: 1.60141, precision: 0.900 recall: 0.871 f1: 0.885 accuracy: 0.987 
training batch:   140, loss: 1.67959, precision: 0.935 recall: 0.879 f1: 0.906 accuracy: 0.992 
training batch:   160, loss: 2.16442, precision: 0.837 recall: 0.818 f1: 0.828 accuracy: 0.972 
training batch:   180, loss: 1.51393, precision: 0.784 recall: 0.829 f1: 0.806 accuracy: 0.978 
training batch:   200, loss: 1.54757, precision: 0.842 recall: 0.923 f1: 0.881 accuracy: 0.986 
training batch:   220, loss: 2.36132, precision: 0.918 recall: 0.789 f1: 0.849 accuracy: 0.951 
training batch:   240, loss: 1.56030, precision: 0.843 recall: 0.878 f1: 0.860 accuracy: 0.985 
training batch:   260, loss: 1.70017, precision: 0.828 recall: 0.774 f1: 0.800 accuracy: 0.971 
training batch:   280, loss: 1.44422, precision: 0.935 recall: 0.860 f1: 0.896 accuracy: 0.984 
training batch:   300, loss: 1.30311, precision: 0.902 recall: 0.860 f1: 0.881 accuracy: 0.982 
training batch:   320, loss: 1.70407, precision: 0.938 recall: 0.897 f1: 0.917 accuracy: 0.986 
training batch:   340, loss: 1.67275, precision: 0.907 recall: 0.929 f1: 0.918 accuracy: 0.976 
training batch:   360, loss: 1.52253, precision: 0.789 recall: 0.833 f1: 0.811 accuracy: 0.979 
training batch:   380, loss: 1.97590, precision: 0.902 recall: 0.807 f1: 0.852 accuracy: 0.973 
training batch:   400, loss: 2.22311, precision: 0.917 recall: 0.815 f1: 0.863 accuracy: 0.978 
training batch:   420, loss: 1.54469, precision: 0.900 recall: 0.818 f1: 0.857 accuracy: 0.984 
training batch:   440, loss: 1.95673, precision: 0.778 recall: 0.745 f1: 0.761 accuracy: 0.972 
training batch:   460, loss: 1.79824, precision: 0.692 recall: 0.730 f1: 0.711 accuracy: 0.980 
training batch:   480, loss: 1.37727, precision: 0.854 recall: 0.875 f1: 0.864 accuracy: 0.981 
training batch:   500, loss: 1.96956, precision: 0.878 recall: 0.878 f1: 0.878 accuracy: 0.980 
training batch:   520, loss: 2.28897, precision: 0.745 recall: 0.729 f1: 0.737 accuracy: 0.976 
training batch:   540, loss: 1.29866, precision: 0.931 recall: 0.818 f1: 0.871 accuracy: 0.988 
training batch:   560, loss: 1.07485, precision: 0.878 recall: 0.818 f1: 0.847 accuracy: 0.976 
training batch:   580, loss: 1.89239, precision: 0.922 recall: 0.797 f1: 0.855 accuracy: 0.982 
training batch:   600, loss: 2.13520, precision: 0.838 recall: 0.816 f1: 0.827 accuracy: 0.977 
training batch:   620, loss: 1.62772, precision: 0.830 recall: 0.812 f1: 0.821 accuracy: 0.979 
training batch:   640, loss: 1.94946, precision: 0.904 recall: 0.887 f1: 0.895 accuracy: 0.981 
training batch:   660, loss: 1.35593, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.978 
training batch:   680, loss: 1.51527, precision: 0.898 recall: 0.786 f1: 0.838 accuracy: 0.984 
training batch:   700, loss: 1.15055, precision: 0.882 recall: 0.909 f1: 0.896 accuracy: 0.991 
training batch:   720, loss: 1.08305, precision: 0.974 recall: 0.905 f1: 0.938 accuracy: 0.992 
start evaluate engines...
label: ORG, precision: 0.799 recall: 0.666 f1: 0.715 accuracy: 0.000 
label: PER, precision: 0.865 recall: 0.844 f1: 0.847 accuracy: 0.000 
label: LOC, precision: 0.808 recall: 0.828 f1: 0.811 accuracy: 0.000 
time consumption:6.72(min), precision: 0.851 recall: 0.805 f1: 0.826 accuracy: 0.977 
saved the new best model with f1: 0.826
epoch:5/300
training batch:    20, loss: 1.46978, precision: 0.896 recall: 0.878 f1: 0.887 accuracy: 0.983 
training batch:    40, loss: 1.35245, precision: 0.875 recall: 0.860 f1: 0.867 accuracy: 0.987 
training batch:    60, loss: 1.09024, precision: 0.929 recall: 0.886 f1: 0.907 accuracy: 0.987 
training batch:    80, loss: 1.36735, precision: 0.808 recall: 0.894 f1: 0.848 accuracy: 0.984 
training batch:   100, loss: 1.27590, precision: 0.872 recall: 0.911 f1: 0.891 accuracy: 0.987 
training batch:   120, loss: 0.76051, precision: 0.871 recall: 0.871 f1: 0.871 accuracy: 0.984 
training batch:   140, loss: 0.91727, precision: 0.913 recall: 0.875 f1: 0.894 accuracy: 0.984 
training batch:   160, loss: 0.72897, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.988 
training batch:   180, loss: 1.84366, precision: 0.945 recall: 0.839 f1: 0.889 accuracy: 0.972 
training batch:   200, loss: 1.23141, precision: 0.863 recall: 0.863 f1: 0.863 accuracy: 0.986 
training batch:   220, loss: 0.66631, precision: 0.943 recall: 0.846 f1: 0.892 accuracy: 0.989 
training batch:   240, loss: 1.86189, precision: 0.744 recall: 0.674 f1: 0.707 accuracy: 0.965 
training batch:   260, loss: 1.15035, precision: 0.966 recall: 0.848 f1: 0.903 accuracy: 0.988 
training batch:   280, loss: 1.09997, precision: 0.923 recall: 0.889 f1: 0.906 accuracy: 0.986 
training batch:   300, loss: 2.53472, precision: 0.806 recall: 0.674 f1: 0.734 accuracy: 0.975 
training batch:   320, loss: 1.83215, precision: 0.891 recall: 0.854 f1: 0.872 accuracy: 0.979 
training batch:   340, loss: 1.06960, precision: 0.872 recall: 0.850 f1: 0.861 accuracy: 0.987 
training batch:   360, loss: 0.84471, precision: 0.833 recall: 0.882 f1: 0.857 accuracy: 0.989 
training batch:   380, loss: 2.33114, precision: 0.878 recall: 0.766 f1: 0.818 accuracy: 0.974 
training batch:   400, loss: 0.74459, precision: 0.875 recall: 0.897 f1: 0.886 accuracy: 0.986 
training batch:   420, loss: 1.30443, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.978 
training batch:   440, loss: 0.77917, precision: 0.947 recall: 0.900 f1: 0.923 accuracy: 0.992 
training batch:   460, loss: 1.90610, precision: 0.982 recall: 0.862 f1: 0.918 accuracy: 0.979 
training batch:   480, loss: 1.55139, precision: 0.820 recall: 0.788 f1: 0.804 accuracy: 0.982 
training batch:   500, loss: 0.93028, precision: 0.870 recall: 0.909 f1: 0.889 accuracy: 0.989 
training batch:   520, loss: 2.55497, precision: 0.918 recall: 0.848 f1: 0.882 accuracy: 0.967 
training batch:   540, loss: 0.98573, precision: 0.879 recall: 0.906 f1: 0.892 accuracy: 0.983 
training batch:   560, loss: 1.98207, precision: 0.883 recall: 0.841 f1: 0.862 accuracy: 0.972 
training batch:   580, loss: 1.84084, precision: 0.927 recall: 0.850 f1: 0.887 accuracy: 0.971 
training batch:   600, loss: 1.36615, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.982 
training batch:   620, loss: 1.15188, precision: 0.898 recall: 0.898 f1: 0.898 accuracy: 0.981 
training batch:   640, loss: 0.91567, precision: 0.903 recall: 0.800 f1: 0.848 accuracy: 0.987 
training batch:   660, loss: 1.45044, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.980 
training batch:   680, loss: 1.15127, precision: 0.787 recall: 0.841 f1: 0.813 accuracy: 0.979 
training batch:   700, loss: 1.30464, precision: 0.938 recall: 0.857 f1: 0.896 accuracy: 0.985 
training batch:   720, loss: 1.41345, precision: 0.829 recall: 0.773 f1: 0.800 accuracy: 0.969 
start evaluate engines...
label: ORG, precision: 0.766 recall: 0.746 f1: 0.749 accuracy: 0.000 
label: PER, precision: 0.890 recall: 0.863 f1: 0.868 accuracy: 0.000 
label: LOC, precision: 0.807 recall: 0.839 f1: 0.816 accuracy: 0.000 
time consumption:6.87(min), precision: 0.844 recall: 0.838 f1: 0.840 accuracy: 0.979 
saved the new best model with f1: 0.840
epoch:6/300
training batch:    20, loss: 0.81378, precision: 0.840 recall: 0.875 f1: 0.857 accuracy: 0.988 
training batch:    40, loss: 1.36365, precision: 0.846 recall: 0.830 f1: 0.838 accuracy: 0.980 
training batch:    60, loss: 1.16434, precision: 0.878 recall: 0.878 f1: 0.878 accuracy: 0.988 
training batch:    80, loss: 1.99939, precision: 0.868 recall: 0.902 f1: 0.885 accuracy: 0.979 
training batch:   100, loss: 0.82953, precision: 0.896 recall: 0.915 f1: 0.905 accuracy: 0.981 
training batch:   120, loss: 0.88169, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.985 
training batch:   140, loss: 1.13918, precision: 0.896 recall: 0.878 f1: 0.887 accuracy: 0.983 
training batch:   160, loss: 0.49997, precision: 0.935 recall: 0.915 f1: 0.925 accuracy: 0.996 
training batch:   180, loss: 0.88464, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.985 
training batch:   200, loss: 0.83225, precision: 0.930 recall: 0.946 f1: 0.938 accuracy: 0.993 
training batch:   220, loss: 1.27057, precision: 1.000 recall: 0.912 f1: 0.954 accuracy: 0.990 
training batch:   240, loss: 0.75596, precision: 1.000 recall: 0.879 f1: 0.935 accuracy: 0.994 
training batch:   260, loss: 0.93368, precision: 0.986 recall: 0.972 f1: 0.979 accuracy: 0.988 
training batch:   280, loss: 1.04648, precision: 0.927 recall: 0.826 f1: 0.874 accuracy: 0.983 
training batch:   300, loss: 1.45431, precision: 0.863 recall: 0.846 f1: 0.854 accuracy: 0.974 
training batch:   320, loss: 1.27192, precision: 0.821 recall: 0.842 f1: 0.831 accuracy: 0.987 
training batch:   340, loss: 1.34059, precision: 0.857 recall: 0.774 f1: 0.814 accuracy: 0.984 
training batch:   360, loss: 1.01293, precision: 0.868 recall: 0.733 f1: 0.795 accuracy: 0.986 
training batch:   380, loss: 1.01597, precision: 0.765 recall: 0.867 f1: 0.812 accuracy: 0.979 
training batch:   400, loss: 0.98045, precision: 0.921 recall: 0.795 f1: 0.854 accuracy: 0.989 
training batch:   420, loss: 0.79441, precision: 0.773 recall: 0.739 f1: 0.756 accuracy: 0.988 
training batch:   440, loss: 1.27638, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.984 
training batch:   460, loss: 0.85132, precision: 0.870 recall: 0.909 f1: 0.889 accuracy: 0.987 
training batch:   480, loss: 1.56481, precision: 0.851 recall: 0.784 f1: 0.816 accuracy: 0.977 
training batch:   500, loss: 1.65401, precision: 0.891 recall: 0.788 f1: 0.837 accuracy: 0.982 
training batch:   520, loss: 0.84472, precision: 0.833 recall: 0.806 f1: 0.820 accuracy: 0.983 
training batch:   540, loss: 0.63132, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.993 
training batch:   560, loss: 0.98976, precision: 0.917 recall: 0.815 f1: 0.863 accuracy: 0.984 
training batch:   580, loss: 0.95782, precision: 0.837 recall: 0.800 f1: 0.818 accuracy: 0.982 
training batch:   600, loss: 0.92840, precision: 0.885 recall: 0.793 f1: 0.836 accuracy: 0.977 
training batch:   620, loss: 1.58610, precision: 0.895 recall: 0.791 f1: 0.840 accuracy: 0.980 
training batch:   640, loss: 1.65756, precision: 0.851 recall: 0.851 f1: 0.851 accuracy: 0.969 
training batch:   660, loss: 0.70605, precision: 0.904 recall: 0.904 f1: 0.904 accuracy: 0.991 
training batch:   680, loss: 1.23794, precision: 0.814 recall: 0.833 f1: 0.824 accuracy: 0.976 
training batch:   700, loss: 1.01405, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.986 
training batch:   720, loss: 2.48855, precision: 0.897 recall: 0.803 f1: 0.847 accuracy: 0.961 
start evaluate engines...
label: ORG, precision: 0.744 recall: 0.765 f1: 0.745 accuracy: 0.000 
label: PER, precision: 0.907 recall: 0.848 f1: 0.867 accuracy: 0.000 
label: LOC, precision: 0.863 recall: 0.817 f1: 0.834 accuracy: 0.000 
time consumption:6.72(min), precision: 0.868 recall: 0.829 f1: 0.846 accuracy: 0.979 
saved the new best model with f1: 0.846
epoch:7/300
training batch:    20, loss: 0.49786, precision: 0.958 recall: 0.793 f1: 0.868 accuracy: 0.989 
training batch:    40, loss: 0.55691, precision: 0.947 recall: 0.878 f1: 0.911 accuracy: 0.995 
training batch:    60, loss: 0.34430, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.998 
training batch:    80, loss: 0.85742, precision: 0.917 recall: 0.846 f1: 0.880 accuracy: 0.976 
training batch:   100, loss: 0.50309, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.995 
training batch:   120, loss: 0.78295, precision: 0.971 recall: 0.846 f1: 0.904 accuracy: 0.982 
training batch:   140, loss: 0.67797, precision: 0.909 recall: 0.938 f1: 0.923 accuracy: 0.990 
training batch:   160, loss: 0.53958, precision: 0.946 recall: 0.964 f1: 0.955 accuracy: 0.997 
training batch:   180, loss: 0.58619, precision: 0.955 recall: 0.933 f1: 0.944 accuracy: 0.993 
training batch:   200, loss: 1.35152, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.986 
training batch:   220, loss: 0.32517, precision: 0.972 recall: 0.946 f1: 0.959 accuracy: 0.999 
training batch:   240, loss: 1.22507, precision: 0.887 recall: 0.839 f1: 0.862 accuracy: 0.984 
training batch:   260, loss: 0.53647, precision: 0.927 recall: 0.927 f1: 0.927 accuracy: 0.995 
training batch:   280, loss: 1.19243, precision: 0.921 recall: 0.935 f1: 0.928 accuracy: 0.983 
training batch:   300, loss: 0.48248, precision: 0.970 recall: 0.914 f1: 0.941 accuracy: 0.993 
training batch:   320, loss: 1.35632, precision: 0.883 recall: 0.869 f1: 0.876 accuracy: 0.982 
training batch:   340, loss: 0.80100, precision: 0.935 recall: 0.915 f1: 0.925 accuracy: 0.987 
training batch:   360, loss: 0.69486, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.987 
training batch:   380, loss: 0.78030, precision: 0.955 recall: 0.914 f1: 0.934 accuracy: 0.989 
training batch:   400, loss: 0.59873, precision: 0.898 recall: 0.957 f1: 0.926 accuracy: 0.989 
training batch:   420, loss: 1.52646, precision: 0.881 recall: 0.822 f1: 0.851 accuracy: 0.977 
training batch:   440, loss: 1.34940, precision: 0.862 recall: 0.862 f1: 0.862 accuracy: 0.983 
training batch:   460, loss: 1.57286, precision: 0.868 recall: 0.885 f1: 0.876 accuracy: 0.978 
training batch:   480, loss: 1.34496, precision: 0.913 recall: 0.900 f1: 0.906 accuracy: 0.973 
training batch:   500, loss: 1.10684, precision: 0.904 recall: 0.855 f1: 0.879 accuracy: 0.979 
training batch:   520, loss: 0.62145, precision: 0.933 recall: 0.757 f1: 0.836 accuracy: 0.989 
training batch:   540, loss: 1.15290, precision: 0.939 recall: 0.902 f1: 0.920 accuracy: 0.984 
training batch:   560, loss: 1.14086, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.984 
training batch:   580, loss: 1.13197, precision: 0.939 recall: 0.902 f1: 0.920 accuracy: 0.984 
training batch:   600, loss: 0.39689, precision: 0.897 recall: 0.929 f1: 0.912 accuracy: 0.993 
training batch:   620, loss: 0.71723, precision: 0.938 recall: 0.900 f1: 0.918 accuracy: 0.988 
training batch:   640, loss: 0.85419, precision: 0.848 recall: 0.907 f1: 0.876 accuracy: 0.985 
training batch:   660, loss: 0.93844, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.985 
training batch:   680, loss: 1.24810, precision: 0.891 recall: 0.919 f1: 0.905 accuracy: 0.982 
training batch:   700, loss: 2.14064, precision: 0.875 recall: 0.836 f1: 0.855 accuracy: 0.972 
training batch:   720, loss: 0.92448, precision: 0.933 recall: 0.894 f1: 0.913 accuracy: 0.990 
start evaluate engines...
label: ORG, precision: 0.790 recall: 0.733 f1: 0.751 accuracy: 0.000 
label: PER, precision: 0.902 recall: 0.867 f1: 0.876 accuracy: 0.000 
label: LOC, precision: 0.843 recall: 0.839 f1: 0.835 accuracy: 0.000 
time consumption:6.69(min), precision: 0.874 recall: 0.836 f1: 0.853 accuracy: 0.979 
saved the new best model with f1: 0.853
epoch:8/300
training batch:    20, loss: 0.89116, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.978 
training batch:    40, loss: 0.94686, precision: 0.940 recall: 0.904 f1: 0.922 accuracy: 0.991 
training batch:    60, loss: 0.43082, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.995 
training batch:    80, loss: 0.83116, precision: 0.913 recall: 0.857 f1: 0.884 accuracy: 0.989 
training batch:   100, loss: 0.43479, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.993 
training batch:   120, loss: 0.81399, precision: 0.950 recall: 0.934 f1: 0.942 accuracy: 0.983 
training batch:   140, loss: 0.64251, precision: 0.977 recall: 0.915 f1: 0.945 accuracy: 0.994 
training batch:   160, loss: 0.38917, precision: 0.957 recall: 0.938 f1: 0.947 accuracy: 0.996 
training batch:   180, loss: 1.10605, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.982 
training batch:   200, loss: 1.17843, precision: 0.906 recall: 0.806 f1: 0.853 accuracy: 0.982 
training batch:   220, loss: 0.65793, precision: 0.850 recall: 0.944 f1: 0.895 accuracy: 0.988 
training batch:   240, loss: 0.52920, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.997 
training batch:   260, loss: 1.18987, precision: 0.949 recall: 0.933 f1: 0.941 accuracy: 0.986 
training batch:   280, loss: 0.55635, precision: 0.943 recall: 0.868 f1: 0.904 accuracy: 0.991 
training batch:   300, loss: 0.85527, precision: 0.950 recall: 0.905 f1: 0.927 accuracy: 0.985 
training batch:   320, loss: 1.48421, precision: 0.921 recall: 0.829 f1: 0.872 accuracy: 0.987 
training batch:   340, loss: 0.52342, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.992 
training batch:   360, loss: 0.57670, precision: 0.960 recall: 0.906 f1: 0.932 accuracy: 0.984 
training batch:   380, loss: 0.25965, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.996 
training batch:   400, loss: 0.39950, precision: 1.000 recall: 0.943 f1: 0.971 accuracy: 0.995 
training batch:   420, loss: 0.99819, precision: 0.886 recall: 0.848 f1: 0.867 accuracy: 0.987 
training batch:   440, loss: 0.61933, precision: 0.949 recall: 0.982 f1: 0.966 accuracy: 0.995 
training batch:   460, loss: 0.48240, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.997 
training batch:   480, loss: 1.11324, precision: 0.931 recall: 0.857 f1: 0.893 accuracy: 0.984 
training batch:   500, loss: 0.29723, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.995 
training batch:   520, loss: 0.51296, precision: 0.980 recall: 0.961 f1: 0.970 accuracy: 0.994 
training batch:   540, loss: 0.68515, precision: 0.953 recall: 0.976 f1: 0.965 accuracy: 0.990 
training batch:   560, loss: 0.63503, precision: 0.907 recall: 0.907 f1: 0.907 accuracy: 0.990 
training batch:   580, loss: 1.37872, precision: 0.859 recall: 0.859 f1: 0.859 accuracy: 0.981 
training batch:   600, loss: 0.70981, precision: 0.943 recall: 0.868 f1: 0.904 accuracy: 0.986 
training batch:   620, loss: 1.10111, precision: 0.875 recall: 0.891 f1: 0.883 accuracy: 0.981 
training batch:   640, loss: 0.41290, precision: 0.929 recall: 0.839 f1: 0.881 accuracy: 0.995 
training batch:   660, loss: 0.52874, precision: 0.972 recall: 0.897 f1: 0.933 accuracy: 0.989 
training batch:   680, loss: 0.89934, precision: 0.912 recall: 0.861 f1: 0.886 accuracy: 0.992 
training batch:   700, loss: 0.94844, precision: 0.914 recall: 0.842 f1: 0.877 accuracy: 0.985 
training batch:   720, loss: 0.57547, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.985 
start evaluate engines...
label: ORG, precision: 0.756 recall: 0.780 f1: 0.758 accuracy: 0.000 
label: PER, precision: 0.917 recall: 0.855 f1: 0.878 accuracy: 0.000 
label: LOC, precision: 0.848 recall: 0.845 f1: 0.841 accuracy: 0.000 
time consumption:6.72(min), precision: 0.860 recall: 0.847 f1: 0.852 accuracy: 0.978 
epoch:9/300
training batch:    20, loss: 0.75986, precision: 0.958 recall: 0.902 f1: 0.929 accuracy: 0.990 
training batch:    40, loss: 0.40588, precision: 0.961 recall: 0.961 f1: 0.961 accuracy: 0.992 
training batch:    60, loss: 0.63090, precision: 0.907 recall: 0.891 f1: 0.899 accuracy: 0.993 
training batch:    80, loss: 0.55630, precision: 0.898 recall: 0.930 f1: 0.914 accuracy: 0.992 
training batch:   100, loss: 0.40749, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.992 
training batch:   120, loss: 0.51469, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.995 
training batch:   140, loss: 0.22742, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.998 
training batch:   160, loss: 1.12683, precision: 0.929 recall: 0.852 f1: 0.889 accuracy: 0.981 
training batch:   180, loss: 0.57508, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.991 
training batch:   200, loss: 0.28693, precision: 0.962 recall: 0.980 f1: 0.971 accuracy: 0.999 
training batch:   220, loss: 0.32810, precision: 0.921 recall: 0.921 f1: 0.921 accuracy: 0.995 
training batch:   240, loss: 0.54111, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.995 
training batch:   260, loss: 0.52443, precision: 0.875 recall: 0.840 f1: 0.857 accuracy: 0.995 
training batch:   280, loss: 0.73353, precision: 0.885 recall: 0.852 f1: 0.868 accuracy: 0.992 
training batch:   300, loss: 1.01647, precision: 0.868 recall: 0.852 f1: 0.860 accuracy: 0.976 
training batch:   320, loss: 0.55782, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.993 
training batch:   340, loss: 0.50903, precision: 0.929 recall: 0.945 f1: 0.937 accuracy: 0.989 
training batch:   360, loss: 0.59568, precision: 0.962 recall: 0.949 f1: 0.955 accuracy: 0.991 
training batch:   380, loss: 0.57569, precision: 0.914 recall: 0.865 f1: 0.889 accuracy: 0.993 
training batch:   400, loss: 0.54577, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.993 
training batch:   420, loss: 0.61481, precision: 0.918 recall: 0.882 f1: 0.900 accuracy: 0.987 
training batch:   440, loss: 0.49391, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.989 
training batch:   460, loss: 1.29073, precision: 0.868 recall: 0.846 f1: 0.857 accuracy: 0.977 
training batch:   480, loss: 0.58166, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.996 
training batch:   500, loss: 0.72186, precision: 0.940 recall: 0.959 f1: 0.949 accuracy: 0.993 
training batch:   520, loss: 0.76279, precision: 0.917 recall: 0.936 f1: 0.926 accuracy: 0.990 
training batch:   540, loss: 0.21796, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.997 
training batch:   560, loss: 0.73798, precision: 0.929 recall: 0.951 f1: 0.940 accuracy: 0.990 
training batch:   580, loss: 0.49725, precision: 0.964 recall: 0.900 f1: 0.931 accuracy: 0.994 
training batch:   600, loss: 0.47869, precision: 0.981 recall: 0.962 f1: 0.971 accuracy: 0.993 
training batch:   620, loss: 1.35336, precision: 0.833 recall: 0.778 f1: 0.805 accuracy: 0.979 
training batch:   640, loss: 0.74741, precision: 0.857 recall: 0.889 f1: 0.873 accuracy: 0.988 
training batch:   660, loss: 1.55786, precision: 0.937 recall: 0.908 f1: 0.922 accuracy: 0.986 
training batch:   680, loss: 0.84804, precision: 0.934 recall: 0.934 f1: 0.934 accuracy: 0.989 
training batch:   700, loss: 0.52466, precision: 0.875 recall: 0.875 f1: 0.875 accuracy: 0.987 
training batch:   720, loss: 0.36795, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.995 
start evaluate engines...
label: ORG, precision: 0.767 recall: 0.782 f1: 0.766 accuracy: 0.000 
label: PER, precision: 0.913 recall: 0.854 f1: 0.876 accuracy: 0.000 
label: LOC, precision: 0.860 recall: 0.849 f1: 0.849 accuracy: 0.000 
time consumption:6.70(min), precision: 0.867 recall: 0.849 f1: 0.857 accuracy: 0.981 
saved the new best model with f1: 0.857
epoch:10/300
training batch:    20, loss: 0.33417, precision: 0.927 recall: 0.974 f1: 0.950 accuracy: 0.996 
training batch:    40, loss: 0.38688, precision: 0.984 recall: 0.969 f1: 0.977 accuracy: 0.999 
training batch:    60, loss: 0.38363, precision: 0.947 recall: 0.964 f1: 0.956 accuracy: 0.992 
training batch:    80, loss: 0.29793, precision: 1.000 recall: 0.973 f1: 0.986 accuracy: 0.996 
training batch:   100, loss: 0.49578, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.992 
training batch:   120, loss: 0.61759, precision: 0.886 recall: 0.867 f1: 0.876 accuracy: 0.989 
training batch:   140, loss: 0.33174, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.999 
training batch:   160, loss: 0.44983, precision: 0.961 recall: 0.942 f1: 0.951 accuracy: 0.991 
training batch:   180, loss: 0.37491, precision: 0.964 recall: 0.981 f1: 0.972 accuracy: 0.995 
training batch:   200, loss: 0.39197, precision: 0.936 recall: 1.000 f1: 0.967 accuracy: 0.990 
training batch:   220, loss: 0.54027, precision: 0.946 recall: 0.972 f1: 0.959 accuracy: 0.996 
training batch:   240, loss: 0.53858, precision: 1.000 recall: 0.968 f1: 0.984 accuracy: 0.996 
training batch:   260, loss: 0.49576, precision: 0.947 recall: 0.915 f1: 0.931 accuracy: 0.988 
training batch:   280, loss: 0.17654, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   300, loss: 0.92223, precision: 0.887 recall: 0.932 f1: 0.909 accuracy: 0.983 
training batch:   320, loss: 0.24173, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.996 
training batch:   340, loss: 0.44234, precision: 0.961 recall: 0.942 f1: 0.951 accuracy: 0.993 
training batch:   360, loss: 0.65937, precision: 0.951 recall: 0.967 f1: 0.959 accuracy: 0.987 
training batch:   380, loss: 0.65087, precision: 0.867 recall: 0.886 f1: 0.876 accuracy: 0.988 
training batch:   400, loss: 0.37917, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.997 
training batch:   420, loss: 0.52484, precision: 0.917 recall: 0.917 f1: 0.917 accuracy: 0.982 
training batch:   440, loss: 0.28572, precision: 0.960 recall: 0.960 f1: 0.960 accuracy: 0.994 
training batch:   460, loss: 0.24817, precision: 1.000 recall: 0.953 f1: 0.976 accuracy: 0.997 
training batch:   480, loss: 0.77868, precision: 0.870 recall: 0.855 f1: 0.862 accuracy: 0.985 
training batch:   500, loss: 0.25466, precision: 0.943 recall: 1.000 f1: 0.971 accuracy: 0.996 
training batch:   520, loss: 0.27316, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.995 
training batch:   540, loss: 0.58248, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.997 
training batch:   560, loss: 0.62609, precision: 0.943 recall: 0.893 f1: 0.917 accuracy: 0.991 
training batch:   580, loss: 1.00072, precision: 0.864 recall: 0.905 f1: 0.884 accuracy: 0.987 
training batch:   600, loss: 0.77896, precision: 0.913 recall: 0.894 f1: 0.903 accuracy: 0.991 
training batch:   620, loss: 0.75554, precision: 0.955 recall: 0.808 f1: 0.875 accuracy: 0.993 
training batch:   640, loss: 0.48160, precision: 0.964 recall: 0.964 f1: 0.964 accuracy: 0.991 
training batch:   660, loss: 0.27826, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.998 
training batch:   680, loss: 1.11807, precision: 0.862 recall: 0.836 f1: 0.848 accuracy: 0.971 
training batch:   700, loss: 0.39779, precision: 0.988 recall: 0.976 f1: 0.982 accuracy: 0.996 
training batch:   720, loss: 0.52394, precision: 0.979 recall: 0.940 f1: 0.959 accuracy: 0.995 
start evaluate engines...
label: ORG, precision: 0.800 recall: 0.753 f1: 0.767 accuracy: 0.000 
label: PER, precision: 0.888 recall: 0.886 f1: 0.880 accuracy: 0.000 
label: LOC, precision: 0.836 recall: 0.860 f1: 0.843 accuracy: 0.000 
time consumption:6.68(min), precision: 0.865 recall: 0.854 f1: 0.858 accuracy: 0.981 
saved the new best model with f1: 0.858
epoch:11/300
training batch:    20, loss: 0.24474, precision: 0.985 recall: 0.985 f1: 0.985 accuracy: 0.997 
training batch:    40, loss: 0.38627, precision: 0.868 recall: 0.868 f1: 0.868 accuracy: 0.989 
training batch:    60, loss: 0.23010, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.998 
training batch:    80, loss: 0.24400, precision: 0.966 recall: 0.966 f1: 0.966 accuracy: 0.997 
training batch:   100, loss: 0.17694, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.999 
training batch:   120, loss: 0.15863, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.999 
training batch:   140, loss: 0.13838, precision: 0.963 recall: 1.000 f1: 0.981 accuracy: 0.997 
training batch:   160, loss: 0.44114, precision: 0.929 recall: 0.907 f1: 0.918 accuracy: 0.993 
training batch:   180, loss: 0.24892, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.995 
training batch:   200, loss: 0.24936, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.65654, precision: 0.959 recall: 0.887 f1: 0.922 accuracy: 0.987 
training batch:   240, loss: 0.81906, precision: 0.946 recall: 0.854 f1: 0.897 accuracy: 0.983 
training batch:   260, loss: 0.17606, precision: 0.980 recall: 1.000 f1: 0.990 accuracy: 0.999 
training batch:   280, loss: 0.41282, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.998 
training batch:   300, loss: 0.51973, precision: 0.875 recall: 0.913 f1: 0.894 accuracy: 0.991 
training batch:   320, loss: 0.29244, precision: 0.986 recall: 1.000 f1: 0.993 accuracy: 0.997 
training batch:   340, loss: 0.32842, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.993 
training batch:   360, loss: 0.44221, precision: 0.898 recall: 0.936 f1: 0.917 accuracy: 0.994 
training batch:   380, loss: 0.49048, precision: 0.946 recall: 0.930 f1: 0.938 accuracy: 0.990 
training batch:   400, loss: 0.36050, precision: 0.960 recall: 0.980 f1: 0.970 accuracy: 0.994 
training batch:   420, loss: 0.33970, precision: 0.929 recall: 0.929 f1: 0.929 accuracy: 0.993 
training batch:   440, loss: 0.41598, precision: 0.981 recall: 0.946 f1: 0.964 accuracy: 0.993 
training batch:   460, loss: 0.36781, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.991 
training batch:   480, loss: 0.54924, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.994 
training batch:   500, loss: 0.61257, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.997 
training batch:   520, loss: 0.44690, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.997 
training batch:   540, loss: 1.22596, precision: 0.900 recall: 0.800 f1: 0.847 accuracy: 0.987 
training batch:   560, loss: 1.26466, precision: 0.954 recall: 0.902 f1: 0.927 accuracy: 0.992 
training batch:   580, loss: 0.24892, precision: 0.977 recall: 0.977 f1: 0.977 accuracy: 0.998 
training batch:   600, loss: 0.19768, precision: 0.956 recall: 1.000 f1: 0.977 accuracy: 0.997 
training batch:   620, loss: 0.58127, precision: 0.946 recall: 0.964 f1: 0.955 accuracy: 0.983 
training batch:   640, loss: 0.55217, precision: 0.947 recall: 0.878 f1: 0.911 accuracy: 0.988 
training batch:   660, loss: 0.28759, precision: 0.980 recall: 0.961 f1: 0.970 accuracy: 0.996 
training batch:   680, loss: 0.35173, precision: 0.969 recall: 0.939 f1: 0.954 accuracy: 0.990 
training batch:   700, loss: 0.14685, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 1.01461, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.983 
start evaluate engines...
label: ORG, precision: 0.797 recall: 0.760 f1: 0.768 accuracy: 0.000 
label: PER, precision: 0.927 recall: 0.859 f1: 0.884 accuracy: 0.000 
label: LOC, precision: 0.837 recall: 0.852 f1: 0.838 accuracy: 0.000 
time consumption:6.67(min), precision: 0.874 recall: 0.847 f1: 0.859 accuracy: 0.980 
saved the new best model with f1: 0.859
epoch:12/300
training batch:    20, loss: 0.12302, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.996 
training batch:    40, loss: 0.42682, precision: 0.983 recall: 0.952 f1: 0.967 accuracy: 0.996 
training batch:    60, loss: 0.31405, precision: 0.939 recall: 0.912 f1: 0.925 accuracy: 0.993 
training batch:    80, loss: 0.29300, precision: 0.975 recall: 1.000 f1: 0.987 accuracy: 0.997 
training batch:   100, loss: 0.24863, precision: 0.975 recall: 0.951 f1: 0.963 accuracy: 0.999 
training batch:   120, loss: 0.20492, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   140, loss: 0.22284, precision: 1.000 recall: 0.974 f1: 0.987 accuracy: 0.997 
training batch:   160, loss: 0.52711, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.993 
training batch:   180, loss: 0.17202, precision: 0.975 recall: 0.975 f1: 0.975 accuracy: 0.996 
training batch:   200, loss: 0.80835, precision: 0.914 recall: 0.964 f1: 0.938 accuracy: 0.991 
training batch:   220, loss: 0.38278, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.996 
training batch:   240, loss: 0.29231, precision: 0.958 recall: 0.939 f1: 0.948 accuracy: 0.995 
training batch:   260, loss: 0.37117, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.993 
training batch:   280, loss: 0.22172, precision: 0.981 recall: 1.000 f1: 0.990 accuracy: 0.998 
training batch:   300, loss: 0.37979, precision: 0.978 recall: 0.917 f1: 0.946 accuracy: 0.995 
training batch:   320, loss: 0.20135, precision: 0.913 recall: 0.913 f1: 0.913 accuracy: 0.996 
training batch:   340, loss: 0.63934, precision: 0.923 recall: 0.906 f1: 0.914 accuracy: 0.992 
training batch:   360, loss: 0.58381, precision: 0.960 recall: 0.941 f1: 0.950 accuracy: 0.991 
training batch:   380, loss: 0.63632, precision: 0.981 recall: 0.981 f1: 0.981 accuracy: 0.995 
training batch:   400, loss: 0.11633, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   420, loss: 0.65963, precision: 0.909 recall: 0.930 f1: 0.920 accuracy: 0.989 
training batch:   440, loss: 0.35357, precision: 0.909 recall: 0.909 f1: 0.909 accuracy: 0.994 
training batch:   460, loss: 0.22746, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.997 
training batch:   480, loss: 0.12766, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   500, loss: 0.37060, precision: 0.982 recall: 0.964 f1: 0.973 accuracy: 0.994 
training batch:   520, loss: 0.19400, precision: 0.966 recall: 0.983 f1: 0.974 accuracy: 0.998 
training batch:   540, loss: 0.37920, precision: 0.922 recall: 0.940 f1: 0.931 accuracy: 0.993 
training batch:   560, loss: 0.60016, precision: 0.917 recall: 0.815 f1: 0.863 accuracy: 0.994 
training batch:   580, loss: 0.19040, precision: 1.000 recall: 0.971 f1: 0.985 accuracy: 0.998 
training batch:   600, loss: 0.43384, precision: 0.986 recall: 0.973 f1: 0.979 accuracy: 0.998 
training batch:   620, loss: 0.49343, precision: 0.954 recall: 0.939 f1: 0.947 accuracy: 0.992 
training batch:   640, loss: 0.16817, precision: 1.000 recall: 0.964 f1: 0.981 accuracy: 0.998 
training batch:   660, loss: 0.38879, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.991 
training batch:   680, loss: 0.67567, precision: 0.945 recall: 0.912 f1: 0.929 accuracy: 0.992 
training batch:   700, loss: 0.08838, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.08724, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
start evaluate engines...
label: ORG, precision: 0.801 recall: 0.778 f1: 0.781 accuracy: 0.000 
label: PER, precision: 0.871 recall: 0.893 f1: 0.875 accuracy: 0.000 
label: LOC, precision: 0.846 recall: 0.849 f1: 0.841 accuracy: 0.000 
time consumption:6.68(min), precision: 0.864 recall: 0.858 f1: 0.860 accuracy: 0.981 
saved the new best model with f1: 0.860
epoch:13/300
training batch:    20, loss: 0.23550, precision: 0.944 recall: 0.911 f1: 0.927 accuracy: 0.996 
training batch:    40, loss: 0.12711, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:    60, loss: 0.14951, precision: 0.949 recall: 0.974 f1: 0.961 accuracy: 0.997 
training batch:    80, loss: 0.36147, precision: 0.950 recall: 0.950 f1: 0.950 accuracy: 0.996 
training batch:   100, loss: 0.21345, precision: 0.938 recall: 0.938 f1: 0.938 accuracy: 0.997 
training batch:   120, loss: 0.19506, precision: 1.000 recall: 0.962 f1: 0.981 accuracy: 0.997 
training batch:   140, loss: 0.18481, precision: 0.971 recall: 1.000 f1: 0.985 accuracy: 0.998 
training batch:   160, loss: 0.44854, precision: 0.960 recall: 0.941 f1: 0.950 accuracy: 0.990 
training batch:   180, loss: 0.52065, precision: 0.957 recall: 0.957 f1: 0.957 accuracy: 0.994 
training batch:   200, loss: 0.35858, precision: 0.967 recall: 0.983 f1: 0.975 accuracy: 0.996 
training batch:   220, loss: 0.27458, precision: 0.977 recall: 0.933 f1: 0.955 accuracy: 0.994 
training batch:   240, loss: 0.14042, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.995 
training batch:   260, loss: 0.37377, precision: 0.932 recall: 0.911 f1: 0.921 accuracy: 0.991 
training batch:   280, loss: 0.38871, precision: 0.942 recall: 0.980 f1: 0.961 accuracy: 0.992 
training batch:   300, loss: 0.21629, precision: 0.956 recall: 0.977 f1: 0.966 accuracy: 0.996 
training batch:   320, loss: 0.15042, precision: 0.979 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   340, loss: 0.33612, precision: 0.977 recall: 0.933 f1: 0.955 accuracy: 0.997 
training batch:   360, loss: 0.39336, precision: 0.946 recall: 0.981 f1: 0.964 accuracy: 0.996 
training batch:   380, loss: 0.23041, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   400, loss: 0.17226, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.999 
training batch:   420, loss: 0.33510, precision: 0.930 recall: 0.952 f1: 0.941 accuracy: 0.997 
training batch:   440, loss: 0.22643, precision: 1.000 recall: 0.940 f1: 0.969 accuracy: 0.990 
training batch:   460, loss: 0.23533, precision: 0.972 recall: 0.921 f1: 0.946 accuracy: 0.997 
training batch:   480, loss: 0.13447, precision: 0.982 recall: 1.000 f1: 0.991 accuracy: 0.998 
training batch:   500, loss: 0.21831, precision: 1.000 recall: 0.979 f1: 0.989 accuracy: 0.996 
training batch:   520, loss: 0.60883, precision: 0.955 recall: 0.928 f1: 0.941 accuracy: 0.991 
training batch:   540, loss: 0.39766, precision: 0.941 recall: 0.914 f1: 0.928 accuracy: 0.992 
training batch:   560, loss: 0.17681, precision: 0.978 recall: 0.978 f1: 0.978 accuracy: 0.999 
training batch:   580, loss: 0.52320, precision: 0.908 recall: 0.967 f1: 0.937 accuracy: 0.985 
training batch:   600, loss: 0.43353, precision: 0.983 recall: 0.967 f1: 0.975 accuracy: 0.994 
training batch:   620, loss: 0.92548, precision: 0.981 recall: 0.930 f1: 0.955 accuracy: 0.992 
training batch:   640, loss: 0.13315, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   660, loss: 0.21323, precision: 1.000 recall: 0.956 f1: 0.977 accuracy: 0.997 
training batch:   680, loss: 0.92134, precision: 0.930 recall: 0.964 f1: 0.946 accuracy: 0.980 
training batch:   700, loss: 2.06022, precision: 0.972 recall: 0.814 f1: 0.886 accuracy: 0.966 
training batch:   720, loss: 0.50172, precision: 0.955 recall: 0.928 f1: 0.941 accuracy: 0.993 
start evaluate engines...
label: ORG, precision: 0.828 recall: 0.753 f1: 0.781 accuracy: 0.000 
label: PER, precision: 0.930 recall: 0.850 f1: 0.881 accuracy: 0.000 
label: LOC, precision: 0.856 recall: 0.871 f1: 0.858 accuracy: 0.000 
time consumption:6.76(min), precision: 0.889 recall: 0.849 f1: 0.867 accuracy: 0.981 
saved the new best model with f1: 0.867
epoch:14/300
training batch:    20, loss: 0.33985, precision: 0.949 recall: 1.000 f1: 0.974 accuracy: 0.996 
training batch:    40, loss: 0.28563, precision: 0.945 recall: 0.963 f1: 0.954 accuracy: 0.997 
training batch:    60, loss: 0.34924, precision: 0.909 recall: 1.000 f1: 0.952 accuracy: 0.990 
training batch:    80, loss: 0.11466, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.999 
training batch:   100, loss: 0.19084, precision: 0.981 recall: 1.000 f1: 0.991 accuracy: 0.998 
training batch:   120, loss: 0.14600, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.999 
training batch:   140, loss: 0.30132, precision: 0.961 recall: 0.925 f1: 0.942 accuracy: 0.991 
training batch:   160, loss: 0.12919, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.997 
training batch:   180, loss: 0.17911, precision: 0.985 recall: 1.000 f1: 0.992 accuracy: 0.999 
training batch:   200, loss: 0.05016, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   220, loss: 0.24935, precision: 0.967 recall: 0.983 f1: 0.975 accuracy: 0.995 
training batch:   240, loss: 0.18536, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.997 
training batch:   260, loss: 0.06914, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   280, loss: 0.15337, precision: 0.981 recall: 1.000 f1: 0.991 accuracy: 0.999 
training batch:   300, loss: 0.15739, precision: 1.000 recall: 0.978 f1: 0.989 accuracy: 0.997 
training batch:   320, loss: 0.21827, precision: 1.000 recall: 0.980 f1: 0.990 accuracy: 0.997 
training batch:   340, loss: 0.25017, precision: 0.926 recall: 0.926 f1: 0.926 accuracy: 0.995 
training batch:   360, loss: 0.53899, precision: 0.980 recall: 0.923 f1: 0.950 accuracy: 0.993 
training batch:   380, loss: 0.23058, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.997 
training batch:   400, loss: 0.54434, precision: 0.956 recall: 0.956 f1: 0.956 accuracy: 0.995 
training batch:   420, loss: 0.13439, precision: 0.969 recall: 1.000 f1: 0.984 accuracy: 0.999 
training batch:   440, loss: 0.32130, precision: 1.000 recall: 0.957 f1: 0.978 accuracy: 0.992 
training batch:   460, loss: 0.24368, precision: 0.936 recall: 0.957 f1: 0.946 accuracy: 0.992 
training batch:   480, loss: 0.15797, precision: 1.000 recall: 0.971 f1: 0.986 accuracy: 0.997 
training batch:   500, loss: 0.21727, precision: 0.982 recall: 0.982 f1: 0.982 accuracy: 0.999 
training batch:   520, loss: 0.20192, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 0.998 
training batch:   540, loss: 0.25378, precision: 0.982 recall: 1.000 f1: 0.991 accuracy: 0.998 
training batch:   560, loss: 0.39165, precision: 0.947 recall: 0.964 f1: 0.956 accuracy: 0.995 
training batch:   580, loss: 0.37265, precision: 0.952 recall: 0.938 f1: 0.945 accuracy: 0.991 
training batch:   600, loss: 0.15793, precision: 0.972 recall: 0.972 f1: 0.972 accuracy: 0.996 
training batch:   620, loss: 0.26800, precision: 0.975 recall: 0.929 f1: 0.951 accuracy: 0.992 
training batch:   640, loss: 0.26354, precision: 0.929 recall: 0.963 f1: 0.945 accuracy: 0.992 
training batch:   660, loss: 0.33005, precision: 0.980 recall: 0.925 f1: 0.951 accuracy: 0.992 
training batch:   680, loss: 0.13795, precision: 0.966 recall: 0.982 f1: 0.974 accuracy: 0.999 
training batch:   700, loss: 0.32027, precision: 0.925 recall: 0.925 f1: 0.925 accuracy: 0.996 
training batch:   720, loss: 0.25451, precision: 0.971 recall: 0.943 f1: 0.957 accuracy: 0.997 
start evaluate engines...
